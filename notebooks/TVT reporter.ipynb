{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kuhar 0.7965277777777777\n",
      "motionsense 0.8872881355932204\n",
      "uci 0.8855072463768117\n",
      "wisdm 0.7693990755007704\n",
      "realworld_thigh 0.6959972394755003\n",
      "realworld_waist 0.663233024691358\n"
     ]
    }
   ],
   "source": [
    "datasets = ['kuhar', 'motionsense', 'uci', 'wisdm', 'realworld_thigh', 'realworld_waist']\n",
    "for dataset in datasets:\n",
    "    with open(f'../execute_once_experiments/TVT_sb_tdom_no_reducer/scores/TVT_sb_no_reducer_{dataset}.yaml') as f:\n",
    "        scores = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        print(dataset, scores['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['kuhar', 'motionsense', 'uci', 'wisdm', 'realworld_thigh', 'realworld_waist']\n",
    "models = ['umap', 'ae', 'tae', 'convae', 'convtae']\n",
    "percentages = [25, 50, 75, 100]\n",
    "\n",
    "data = []\n",
    "new_data = {\n",
    "    'dataset': None,\n",
    "    'model': None,\n",
    "    'percentage': None,\n",
    "    'score': None,\n",
    "    'knn': None,\n",
    "    'rf': None,\n",
    "    'svm': None\n",
    "}\n",
    "for dataset in datasets:\n",
    "    for model in models:\n",
    "        for percentage in percentages:\n",
    "            filename = f'../execute_once_experiments/TVT_sb_best_found_2023/scores/TVT_sb_{model}_{dataset}_P{percentage}.yaml'\n",
    "            with open(filename) as f:\n",
    "                scores = yaml.load(f, Loader=yaml.FullLoader)\n",
    "                new_data['dataset'] = dataset\n",
    "                new_data['model'] = model\n",
    "                new_data['percentage'] = percentage\n",
    "                new_data['score'] = scores['score']\n",
    "                new_data['knn'] = scores['KNN-5-accuracy (mean)']\n",
    "                new_data['rf'] = scores['randomforest-100-accuracy (mean)']\n",
    "                new_data['svm'] = scores['SVM-rbf-C1.0-accuracy (mean)']\n",
    "                data.append(new_data.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+--------------+------------+------------+------------+------------+------------+------------+\n",
      "|    | model   |   percentage | UCI        | MS         | KH         | WISDM      | RW Thigh   | RW Waist   |\n",
      "|----+---------+--------------+------------+------------+------------+------------+------------+------------|\n",
      "|  0 | ae      |           25 | 72.8%(SVM) | 79.5%(KNN) | 66.7%(SVM) | 70.2%(KNN) | 65.8%(SVM) | 60.6%(SVM) |\n",
      "|  1 | ae      |           75 | 73.6%(SVM) | 79.7%(KNN) | 68.1%(SVM) | 70.7%(RF)  | 68.9%(RF)  | 60.5%(SVM) |\n",
      "|  2 | convae  |           25 | 20.0%(KNN) | 79.8%(KNN) | 63.9%(KNN) | 66.0%(RF)  | 61.1%(KNN) | 68.4%(SVM) |\n",
      "|  3 | convae  |           75 | 68.6%(KNN) | 73.7%(KNN) | 66.0%(KNN) | 20.0%(KNN) | 72.7%(KNN) | 16.7%(RF)  |\n",
      "|  4 | convtae |           25 | 74.8%(RF)  | 73.7%(RF)  | 59.7%(SVM) | 65.8%(RF)  | 66.8%(RF)  | 67.3%(SVM) |\n",
      "|  5 | convtae |           75 | 63.3%(RF)  | 60.2%(RF)  | 63.1%(RF)  | 69.6%(RF)  | 48.0%(RF)  | 58.9%(RF)  |\n",
      "|  6 | tae     |           25 | 70.5%(RF)  | 75.2%(RF)  | 65.3%(SVM) | 67.1%(RF)  | 62.8%(RF)  | 65.9%(SVM) |\n",
      "|  7 | tae     |           75 | 69.9%(RF)  | 73.2%(RF)  | 67.4%(KNN) | 71.4%(RF)  | 60.5%(RF)  | 64.2%(SVM) |\n",
      "|  8 | umap    |           25 | 65.7%(RF)  | 74.8%(RF)  | 59.0%(KNN) | 60.1%(RF)  | 59.7%(KNN) | 55.2%(RF)  |\n",
      "|  9 | umap    |           75 | 65.7%(RF)  | 76.1%(RF)  | 58.3%(KNN) | 59.9%(SVM) | 62.4%(RF)  | 53.4%(RF)  |\n",
      "+----+---------+--------------+------------+------------+------------+------------+------------+------------+\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(data)\n",
    "# Drop rows with percentage 100 and 50\n",
    "data = data[(data['percentage'] != 100) & (data['percentage'] != 50)]\n",
    "# Add column with best string for each row\n",
    "data['best'] = data[['knn', 'rf', 'svm']].idxmax(axis=1)\n",
    "rows = []\n",
    "for key, group in data.groupby(['model', 'percentage']):\n",
    "    group.drop(['model', 'percentage', 'knn', 'rf', 'svm'], axis=1, inplace=True)\n",
    "    # Round numbers\n",
    "    \n",
    "    group = group.set_index('dataset')\n",
    "    group['score'] = group['score'].apply(lambda x: round(x*100, 1))\n",
    "    group['VALUE'] = (group['score']).astype(str) + '%(' + group['best'].apply(str.upper) + ')'\n",
    "    group = group.drop(['score', 'best'], axis=1)\n",
    "    # print(group)\n",
    "    group = group.T\n",
    "    \n",
    "    # print(group.loc['best'], '\\nnnn')\n",
    "    # Add key\n",
    "    group['model'] = key[0]\n",
    "    group['percentage'] = key[1]\n",
    "    rows.append(group)\n",
    "table3 = pd.concat(rows)\n",
    "# Reorder columns\n",
    "# print(tabulate(table3, headers='keys', tablefmt='psql'))\n",
    "table3 = table3[['model', 'percentage', 'uci', 'motionsense', 'kuhar', 'wisdm', 'realworld_thigh', 'realworld_waist']]\n",
    "table3 = table3.reset_index(drop=True)\n",
    "# Change column names\n",
    "table3 = table3.rename(columns={'uci': 'UCI', 'motionsense': 'MS', 'kuhar': 'KH', 'wisdm': 'WISDM', 'realworld_thigh': 'RW Thigh', 'realworld_waist': 'RW Waist'})\n",
    "print(tabulate(table3, headers='keys', tablefmt='psql'))\n",
    "# display(table3)\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['kuhar', 'motionsense', 'uci', 'wisdm', 'realworld_thigh', 'realworld_waist']\n",
    "datasets = ['wisdm', 'realworld_thigh', 'realworld_waist']\n",
    "\n",
    "data = []\n",
    "new_data = {\n",
    "    'dataset': None,\n",
    "    'experiment': None,\n",
    "    'knn': None,\n",
    "    'rf': None,\n",
    "    'svm': None,\n",
    "    'score': None\n",
    "}\n",
    "experiments = ['TVT_sb_fdom_no_reducer', 'TVT_sb_fdom_acc_no_reducer', 'TVT_sb_fdom_gyr_no_reducer'] \n",
    "for dataset in datasets:\n",
    "    for experiment in experiments:\n",
    "        filename = f'../execute_once_experiments/{experiment}/scores/TVT_sb_no_reducer_{dataset}.yaml'\n",
    "        with open(filename) as f:\n",
    "            scores = yaml.load(f, Loader=yaml.FullLoader)\n",
    "            new_data['dataset'] = dataset\n",
    "            new_data['experiment'] = experiment\n",
    "            new_data['score'] = scores['score']\n",
    "            new_data['knn'] = scores['KNN-5-accuracy (mean)']\n",
    "            new_data['rf'] = scores['randomforest-100-accuracy (mean)']\n",
    "            new_data['svm'] = scores['SVM-rbf-C1.0-accuracy (mean)']\n",
    "            data.append(new_data.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------+----------------------------+----------+----------+----------+----------+\n",
      "|    | dataset         | experiment                 |      knn |       rf |      svm |    score |\n",
      "|----+-----------------+----------------------------+----------+----------+----------+----------|\n",
      "|  0 | wisdm           | TVT_sb_fdom_no_reducer     | 0.862866 | 0.857134 | 0.804314 | 0.862866 |\n",
      "|  1 | wisdm           | TVT_sb_fdom_acc_no_reducer | 0.832666 | 0.834977 | 0.771957 | 0.834977 |\n",
      "|  2 | wisdm           | TVT_sb_fdom_gyr_no_reducer | 0.82681  | 0.829615 | 0.796302 | 0.829615 |\n",
      "|  3 | realworld_thigh | TVT_sb_fdom_no_reducer     | 0.637336 | 0.802692 | 0.748102 | 0.802692 |\n",
      "|  4 | realworld_thigh | TVT_sb_fdom_acc_no_reducer | 0.753278 | 0.792892 | 0.730504 | 0.792892 |\n",
      "|  5 | realworld_thigh | TVT_sb_fdom_gyr_no_reducer | 0.542443 | 0.708213 | 0.704624 | 0.708213 |\n",
      "|  6 | realworld_waist | TVT_sb_fdom_no_reducer     | 0.736497 | 0.738503 | 0.743827 | 0.743827 |\n",
      "|  7 | realworld_waist | TVT_sb_fdom_acc_no_reducer | 0.705247 | 0.716744 | 0.717593 | 0.717593 |\n",
      "|  8 | realworld_waist | TVT_sb_fdom_gyr_no_reducer | 0.68017  | 0.701003 | 0.723765 | 0.723765 |\n",
      "+----+-----------------+----------------------------+----------+----------+----------+----------+\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(pd.DataFrame(data), headers='keys', tablefmt='psql'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
