trial_id,config,error_type,error_message,error_traceback
43ec3582,"{'batch_size': 64, 'num_CL': 3, 'size_CL': 31, 'kernel': 4, 'num_HL': 4, 'latent_dim': 16, 'opt_lr': 1.716478384380778e-05, 'opt_wd': 4.2519049371713674e-07}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacty of 79.15 GiB of which 168.38 MiB is free. Process 1688273 has 24.52 GiB memory in use. Process 1690553 has 492.00 MiB memory in use. Process 298607 has 9.19 GiB memory in use. Process 305672 has 9.82 GiB memory in use. Process 310256 has 7.49 GiB memory in use. Process 313398 has 9.37 GiB memory in use. Process 317912 has 7.47 GiB memory in use. Process 318308 has 10.58 GiB memory in use. Of the allocated memory 6.65 GiB is allocated by PyTorch, and 336.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 136, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
6b63b499,"{'batch_size': 128, 'num_CL': 3, 'size_CL': 31, 'kernel': 4, 'num_HL': 4, 'latent_dim': 15, 'opt_lr': 1.0501100268196329e-05, 'opt_wd': 2.045243755731526e-07}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 170.00 MiB. GPU 0 has a total capacty of 79.15 GiB of which 120.38 MiB is free. Process 1688273 has 24.52 GiB memory in use. Process 1690553 has 492.00 MiB memory in use. Process 298607 has 5.73 GiB memory in use. Process 305672 has 6.57 GiB memory in use. Process 310256 has 9.38 GiB memory in use. Process 313398 has 9.37 GiB memory in use. Process 317912 has 9.26 GiB memory in use. Process 318308 has 13.67 GiB memory in use. Of the allocated memory 6.98 GiB is allocated by PyTorch, and 1.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 136, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
0b3ac505,"{'batch_size': 128, 'num_CL': 3, 'size_CL': 31, 'kernel': 4, 'num_HL': 4, 'latent_dim': 18, 'opt_lr': 1.93895359783268e-05, 'opt_wd': 1.7867777627861292e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 170.00 MiB. GPU 0 has a total capacty of 79.15 GiB of which 8.38 MiB is free. Process 1688273 has 24.52 GiB memory in use. Process 1690553 has 492.00 MiB memory in use. Process 298607 has 5.17 GiB memory in use. Process 305672 has 7.22 GiB memory in use. Process 310256 has 9.38 GiB memory in use. Process 313398 has 9.37 GiB memory in use. Process 317912 has 9.27 GiB memory in use. Process 318308 has 13.67 GiB memory in use. Of the allocated memory 5.87 GiB is allocated by PyTorch, and 854.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 136, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 506, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
ca4b8a75,"{'batch_size': 128, 'num_CL': 3, 'size_CL': 28, 'kernel': 4, 'num_HL': 2, 'latent_dim': 14, 'opt_lr': 5.043387662816841e-05, 'opt_wd': 3.408324357389742e-07}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 410.00 MiB. GPU 0 has a total capacty of 79.15 GiB of which 316.38 MiB is free. Process 1688273 has 24.52 GiB memory in use. Process 1690553 has 492.00 MiB memory in use. Process 298607 has 4.87 GiB memory in use. Process 305672 has 7.23 GiB memory in use. Process 310256 has 9.38 GiB memory in use. Process 313398 has 9.37 GiB memory in use. Process 317912 has 9.27 GiB memory in use. Process 318308 has 13.67 GiB memory in use. Of the allocated memory 3.05 GiB is allocated by PyTorch, and 1.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 136, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1475, in relu
    result = torch.relu(input)
"
c5114364,"{'batch_size': 128, 'num_CL': 3, 'size_CL': 30, 'kernel': 4, 'num_HL': 2, 'latent_dim': 10, 'opt_lr': 2.08318979733734e-05, 'opt_wd': 1.3034217793988795e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 440.00 MiB. GPU 0 has a total capacty of 79.15 GiB of which 178.38 MiB is free. Process 1688273 has 24.52 GiB memory in use. Process 1690553 has 492.00 MiB memory in use. Process 298607 has 5.00 GiB memory in use. Process 305672 has 7.23 GiB memory in use. Process 310256 has 9.38 GiB memory in use. Process 313398 has 9.37 GiB memory in use. Process 317912 has 9.27 GiB memory in use. Process 318308 has 13.67 GiB memory in use. Of the allocated memory 3.40 GiB is allocated by PyTorch, and 1.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 136, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1475, in relu
    result = torch.relu(input)
"
905ee140,"{'batch_size': 128, 'num_CL': 2, 'size_CL': 32, 'kernel': 4, 'num_HL': 4, 'latent_dim': 17, 'opt_lr': 2.3254795191530307e-05, 'opt_wd': 5.249167997941514e-07}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 368.00 MiB. GPU 0 has a total capacty of 79.15 GiB of which 136.38 MiB is free. Process 1688273 has 24.52 GiB memory in use. Process 1690553 has 492.00 MiB memory in use. Process 298607 has 6.06 GiB memory in use. Process 305672 has 7.23 GiB memory in use. Process 310256 has 8.36 GiB memory in use. Process 313398 has 9.37 GiB memory in use. Process 317912 has 9.27 GiB memory in use. Process 318308 has 13.67 GiB memory in use. Of the allocated memory 4.81 GiB is allocated by PyTorch, and 755.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 136, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 444, in _multi_tensor_adam
    device_grads = torch._foreach_add(device_grads, device_params, alpha=weight_decay)
"
37b777ea,"{'batch_size': 128, 'num_CL': 3, 'size_CL': 31, 'kernel': 4, 'num_HL': 4, 'latent_dim': 14, 'opt_lr': 1.3941530262018293e-05, 'opt_wd': 6.01193742620405e-07}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacty of 79.15 GiB of which 316.38 MiB is free. Process 1688273 has 24.52 GiB memory in use. Process 1690553 has 492.00 MiB memory in use. Process 298607 has 5.82 GiB memory in use. Process 305672 has 7.30 GiB memory in use. Process 310256 has 8.36 GiB memory in use. Process 313398 has 9.36 GiB memory in use. Process 317912 has 9.27 GiB memory in use. Process 318308 has 13.67 GiB memory in use. Of the allocated memory 7.42 GiB is allocated by PyTorch, and 1.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 136, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
717220af,"{'batch_size': 128, 'num_CL': 3, 'size_CL': 29, 'kernel': 4, 'num_HL': 3, 'latent_dim': 18, 'opt_lr': 3.347312953773397e-05, 'opt_wd': 3.860005531259933e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 264.00 MiB. GPU 0 has a total capacty of 79.15 GiB of which 116.38 MiB is free. Process 1688273 has 24.52 GiB memory in use. Process 1690553 has 492.00 MiB memory in use. Process 298607 has 6.69 GiB memory in use. Process 305672 has 7.11 GiB memory in use. Process 310256 has 7.87 GiB memory in use. Process 313398 has 9.37 GiB memory in use. Process 317912 has 9.27 GiB memory in use. Process 318308 has 13.67 GiB memory in use. Of the allocated memory 5.26 GiB is allocated by PyTorch, and 928.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 136, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
33d9f0ef,"{'batch_size': 128, 'num_CL': 3, 'size_CL': 30, 'kernel': 4, 'num_HL': 4, 'latent_dim': 14, 'opt_lr': 1.405557102068721e-05, 'opt_wd': 2.8893672234356977e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 318.00 MiB. GPU 0 has a total capacty of 79.15 GiB of which 38.38 MiB is free. Process 1688273 has 24.52 GiB memory in use. Process 1690553 has 492.00 MiB memory in use. Process 298607 has 6.69 GiB memory in use. Process 305672 has 7.11 GiB memory in use. Process 310256 has 7.64 GiB memory in use. Process 313398 has 9.37 GiB memory in use. Process 317912 has 9.57 GiB memory in use. Process 318308 has 13.67 GiB memory in use. Of the allocated memory 7.26 GiB is allocated by PyTorch, and 1.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 136, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
93227a0b,"{'batch_size': 128, 'num_CL': 2, 'size_CL': 28, 'kernel': 4, 'num_HL': 4, 'latent_dim': 17, 'opt_lr': 1.454241415310216e-05, 'opt_wd': 5.351908204129386e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 282.00 MiB. GPU 0 has a total capacty of 79.15 GiB of which 28.38 MiB is free. Process 1688273 has 24.52 GiB memory in use. Process 1690553 has 492.00 MiB memory in use. Process 298607 has 5.64 GiB memory in use. Process 305672 has 7.61 GiB memory in use. Process 310256 has 8.19 GiB memory in use. Process 313398 has 9.38 GiB memory in use. Process 317912 has 9.59 GiB memory in use. Process 318308 has 13.67 GiB memory in use. Of the allocated memory 7.08 GiB is allocated by PyTorch, and 609.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 136, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
c73e9cd1,"{'batch_size': 128, 'num_CL': 3, 'size_CL': 32, 'kernel': 4, 'num_HL': 3, 'latent_dim': 17, 'opt_lr': 1.6095263213914034e-05, 'opt_wd': 9.373215269011753e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 322.00 MiB. GPU 0 has a total capacty of 79.15 GiB of which 308.38 MiB is free. Process 1688273 has 24.52 GiB memory in use. Process 1690553 has 492.00 MiB memory in use. Process 298607 has 7.63 GiB memory in use. Process 305672 has 8.24 GiB memory in use. Process 310256 has 11.66 GiB memory in use. Process 313398 has 9.38 GiB memory in use. Process 317912 has 9.59 GiB memory in use. Process 318308 has 7.29 GiB memory in use. Of the allocated memory 6.41 GiB is allocated by PyTorch, and 722.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 136, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
2e87f6c0,"{'batch_size': 128, 'num_CL': 4, 'size_CL': 31, 'kernel': 3, 'num_HL': 3, 'latent_dim': 18, 'opt_lr': 1.6541369334522024e-05, 'opt_wd': 9.472391922750215e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 304.00 MiB. GPU 0 has a total capacty of 79.15 GiB of which 90.38 MiB is free. Process 1688273 has 24.52 GiB memory in use. Process 1690553 has 492.00 MiB memory in use. Process 298607 has 7.64 GiB memory in use. Process 305672 has 8.51 GiB memory in use. Process 310256 has 11.66 GiB memory in use. Process 313398 has 9.38 GiB memory in use. Process 317912 has 9.59 GiB memory in use. Process 318308 has 7.23 GiB memory in use. Of the allocated memory 6.04 GiB is allocated by PyTorch, and 686.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 136, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
4660cdc8,"{'batch_size': 128, 'num_CL': 4, 'size_CL': 28, 'kernel': 4, 'num_HL': 4, 'latent_dim': 17, 'opt_lr': 1.0163819910428914e-05, 'opt_wd': 8.237882716442544e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacty of 79.15 GiB of which 98.38 MiB is free. Process 1688273 has 24.52 GiB memory in use. Process 1690553 has 492.00 MiB memory in use. Process 298607 has 7.64 GiB memory in use. Process 305672 has 8.49 GiB memory in use. Process 310256 has 11.66 GiB memory in use. Process 313398 has 9.38 GiB memory in use. Process 317912 has 9.59 GiB memory in use. Process 318308 has 7.24 GiB memory in use. Of the allocated memory 6.56 GiB is allocated by PyTorch, and 1.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 136, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1475, in relu
    result = torch.relu(input)
"
459ab9f5,"{'batch_size': 128, 'num_CL': 4, 'size_CL': 30, 'kernel': 4, 'num_HL': 4, 'latent_dim': 17, 'opt_lr': 0.00010706538980418309, 'opt_wd': 7.596770412166748e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 312.00 MiB. GPU 0 has a total capacty of 79.15 GiB of which 100.38 MiB is free. Process 1688273 has 24.52 GiB memory in use. Process 1690553 has 492.00 MiB memory in use. Process 298607 has 7.63 GiB memory in use. Process 305672 has 8.50 GiB memory in use. Process 310256 has 11.66 GiB memory in use. Process 313398 has 9.38 GiB memory in use. Process 317912 has 9.59 GiB memory in use. Process 318308 has 7.24 GiB memory in use. Of the allocated memory 6.12 GiB is allocated by PyTorch, and 1013.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 136, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
27a50a82,"{'batch_size': 128, 'num_CL': 3, 'size_CL': 32, 'kernel': 4, 'num_HL': 3, 'latent_dim': 13, 'opt_lr': 4.335513858725658e-05, 'opt_wd': 4.049709413032194e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 322.00 MiB. GPU 0 has a total capacty of 79.15 GiB of which 290.38 MiB is free. Process 1688273 has 24.52 GiB memory in use. Process 1690553 has 492.00 MiB memory in use. Process 298607 has 7.63 GiB memory in use. Process 305672 has 8.50 GiB memory in use. Process 310256 has 11.66 GiB memory in use. Process 313398 has 9.38 GiB memory in use. Process 317912 has 9.59 GiB memory in use. Process 318308 has 7.04 GiB memory in use. Of the allocated memory 5.56 GiB is allocated by PyTorch, and 986.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 136, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
2f40b75a,"{'batch_size': 128, 'num_CL': 3, 'size_CL': 30, 'kernel': 2, 'num_HL': 3, 'latent_dim': 15, 'opt_lr': 0.0003483982965126044, 'opt_wd': 9.116657433958004e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 292.00 MiB. GPU 0 has a total capacty of 79.15 GiB of which 226.38 MiB is free. Process 1688273 has 24.52 GiB memory in use. Process 1690553 has 492.00 MiB memory in use. Process 298607 has 7.63 GiB memory in use. Process 305672 has 8.50 GiB memory in use. Process 310256 has 11.66 GiB memory in use. Process 313398 has 9.38 GiB memory in use. Process 317912 has 9.59 GiB memory in use. Process 318308 has 7.11 GiB memory in use. Of the allocated memory 5.82 GiB is allocated by PyTorch, and 1.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 136, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
611921d9,"{'batch_size': 128, 'num_CL': 3, 'size_CL': 26, 'kernel': 4, 'num_HL': 4, 'latent_dim': 17, 'opt_lr': 3.97424524744739e-05, 'opt_wd': 9.71158780264113e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 382.00 MiB. GPU 0 has a total capacty of 79.15 GiB of which 346.38 MiB is free. Process 1688273 has 24.52 GiB memory in use. Process 1690553 has 492.00 MiB memory in use. Process 298607 has 7.63 GiB memory in use. Process 305672 has 8.50 GiB memory in use. Process 310256 has 11.66 GiB memory in use. Process 313398 has 9.38 GiB memory in use. Process 317912 has 9.59 GiB memory in use. Process 318308 has 6.99 GiB memory in use. Of the allocated memory 5.04 GiB is allocated by PyTorch, and 1.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 136, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1475, in relu
    result = torch.relu(input)
"
83ac8fd8,"{'batch_size': 128, 'num_CL': 4, 'size_CL': 28, 'kernel': 4, 'num_HL': 4, 'latent_dim': 14, 'opt_lr': 1.3462171134547162e-05, 'opt_wd': 3.4216232678252238e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 272.00 MiB. GPU 0 has a total capacty of 79.15 GiB of which 56.38 MiB is free. Process 1688273 has 24.52 GiB memory in use. Process 1690553 has 492.00 MiB memory in use. Process 298607 has 7.63 GiB memory in use. Process 305672 has 8.52 GiB memory in use. Process 310256 has 11.66 GiB memory in use. Process 313398 has 9.39 GiB memory in use. Process 317912 has 9.59 GiB memory in use. Process 318308 has 7.25 GiB memory in use. Of the allocated memory 5.95 GiB is allocated by PyTorch, and 801.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 136, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
5ee978fc,"{'batch_size': 128, 'num_CL': 4, 'size_CL': 30, 'kernel': 4, 'num_HL': 3, 'latent_dim': 18, 'opt_lr': 3.0780739449403164e-05, 'opt_wd': 6.988453217109925e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 278.00 MiB. GPU 0 has a total capacty of 79.15 GiB of which 52.38 MiB is free. Process 1688273 has 24.52 GiB memory in use. Process 1690553 has 492.00 MiB memory in use. Process 298607 has 7.63 GiB memory in use. Process 305672 has 8.52 GiB memory in use. Process 310256 has 11.66 GiB memory in use. Process 313398 has 9.39 GiB memory in use. Process 317912 has 9.59 GiB memory in use. Process 318308 has 7.26 GiB memory in use. Of the allocated memory 5.54 GiB is allocated by PyTorch, and 1.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 136, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
980078a8,"{'batch_size': 64, 'num_CL': 4, 'size_CL': 30, 'kernel': 3, 'num_HL': 3, 'latent_dim': 17, 'opt_lr': 4.401276631469935e-05, 'opt_wd': 7.480455527700696e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 440.00 MiB. GPU 0 has a total capacty of 79.15 GiB of which 46.38 MiB is free. Process 1688273 has 24.52 GiB memory in use. Process 1690553 has 492.00 MiB memory in use. Process 298607 has 7.91 GiB memory in use. Process 305672 has 8.52 GiB memory in use. Process 310256 has 11.66 GiB memory in use. Process 313398 has 9.39 GiB memory in use. Process 317912 has 8.21 GiB memory in use. Process 318308 has 8.37 GiB memory in use. Of the allocated memory 5.47 GiB is allocated by PyTorch, and 1.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 136, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1475, in relu
    result = torch.relu(input)
"
6a7a6277,"{'batch_size': 128, 'num_CL': 3, 'size_CL': 29, 'kernel': 4, 'num_HL': 4, 'latent_dim': 16, 'opt_lr': 2.9422569527214906e-05, 'opt_wd': 8.341786388160245e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 298.00 MiB. GPU 0 has a total capacty of 79.15 GiB of which 226.31 MiB is free. Process 1688273 has 24.52 GiB memory in use. Process 1690553 has 492.00 MiB memory in use. Process 298607 has 8.72 GiB memory in use. Process 305672 has 8.52 GiB memory in use. Process 310256 has 11.66 GiB memory in use. Process 313398 has 9.39 GiB memory in use. Process 317912 has 8.21 GiB memory in use. Process 318308 has 7.38 GiB memory in use. Of the allocated memory 7.46 GiB is allocated by PyTorch, and 758.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 136, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
0adb0763,"{'batch_size': 128, 'num_CL': 3, 'size_CL': 30, 'kernel': 4, 'num_HL': 4, 'latent_dim': 16, 'opt_lr': 3.454060417629947e-05, 'opt_wd': 8.544416974127716e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 318.00 MiB. GPU 0 has a total capacty of 79.15 GiB of which 158.31 MiB is free. Process 1688273 has 24.52 GiB memory in use. Process 1690553 has 492.00 MiB memory in use. Process 298607 has 7.20 GiB memory in use. Process 305672 has 8.52 GiB memory in use. Process 310256 has 11.67 GiB memory in use. Process 313398 has 9.39 GiB memory in use. Process 317912 has 9.60 GiB memory in use. Process 318308 has 7.57 GiB memory in use. Of the allocated memory 7.99 GiB is allocated by PyTorch, and 1.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 136, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
43b2bd9d,"{'batch_size': 128, 'num_CL': 4, 'size_CL': 32, 'kernel': 4, 'num_HL': 4, 'latent_dim': 17, 'opt_lr': 2.086076871572328e-05, 'opt_wd': 9.566753983836045e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 356.00 MiB. GPU 0 has a total capacty of 79.15 GiB of which 174.31 MiB is free. Process 1688273 has 24.52 GiB memory in use. Process 1690553 has 492.00 MiB memory in use. Process 298607 has 7.53 GiB memory in use. Process 305672 has 6.05 GiB memory in use. Process 310256 has 11.67 GiB memory in use. Process 313398 has 9.39 GiB memory in use. Process 317912 has 9.61 GiB memory in use. Process 318308 has 9.68 GiB memory in use. Of the allocated memory 8.12 GiB is allocated by PyTorch, and 1.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 136, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
1aee398c,"{'batch_size': 64, 'num_CL': 4, 'size_CL': 32, 'kernel': 4, 'num_HL': 2, 'latent_dim': 16, 'opt_lr': 2.2634071789815263e-05, 'opt_wd': 8.634092635224523e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 464.00 MiB. GPU 0 has a total capacty of 79.15 GiB of which 428.31 MiB is free. Process 1688273 has 24.52 GiB memory in use. Process 1690553 has 492.00 MiB memory in use. Process 298607 has 7.53 GiB memory in use. Process 305672 has 5.79 GiB memory in use. Process 310256 has 11.67 GiB memory in use. Process 313398 has 9.39 GiB memory in use. Process 317912 has 9.61 GiB memory in use. Process 318308 has 9.69 GiB memory in use. Of the allocated memory 4.18 GiB is allocated by PyTorch, and 1.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 136, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1475, in relu
    result = torch.relu(input)
"
33cdc849,"{'batch_size': 64, 'num_CL': 3, 'size_CL': 32, 'kernel': 4, 'num_HL': 2, 'latent_dim': 14, 'opt_lr': 1.0073265464456896e-05, 'opt_wd': 4.029333954615334e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 242.00 MiB. GPU 0 has a total capacty of 79.15 GiB of which 104.31 MiB is free. Process 1688273 has 24.52 GiB memory in use. Process 1690553 has 492.00 MiB memory in use. Process 298607 has 7.54 GiB memory in use. Process 305672 has 6.09 GiB memory in use. Process 310256 has 11.67 GiB memory in use. Process 313398 has 9.39 GiB memory in use. Process 317912 has 9.62 GiB memory in use. Process 318308 has 9.70 GiB memory in use. Of the allocated memory 3.55 GiB is allocated by PyTorch, and 2.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 136, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
cc8a2191,"{'batch_size': 128, 'num_CL': 3, 'size_CL': 32, 'kernel': 4, 'num_HL': 2, 'latent_dim': 16, 'opt_lr': 1.0129936449023522e-05, 'opt_wd': 3.881076009432054e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 242.00 MiB. GPU 0 has a total capacty of 79.15 GiB of which 104.31 MiB is free. Process 1688273 has 24.52 GiB memory in use. Process 1690553 has 492.00 MiB memory in use. Process 298607 has 7.54 GiB memory in use. Process 305672 has 6.09 GiB memory in use. Process 310256 has 11.67 GiB memory in use. Process 313398 has 9.39 GiB memory in use. Process 317912 has 9.62 GiB memory in use. Process 318308 has 9.70 GiB memory in use. Of the allocated memory 3.55 GiB is allocated by PyTorch, and 2.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 136, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
04585fb9,"{'batch_size': 64, 'num_CL': 3, 'size_CL': 26, 'kernel': 4, 'num_HL': 3, 'latent_dim': 17, 'opt_lr': 1.914857612919503e-05, 'opt_wd': 2.0544700457454085e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 382.00 MiB. GPU 0 has a total capacty of 79.15 GiB of which 380.31 MiB is free. Process 1688273 has 24.52 GiB memory in use. Process 1690553 has 492.00 MiB memory in use. Process 298607 has 7.55 GiB memory in use. Process 305672 has 5.81 GiB memory in use. Process 310256 has 11.67 GiB memory in use. Process 313398 has 9.39 GiB memory in use. Process 317912 has 9.62 GiB memory in use. Process 318308 has 9.70 GiB memory in use. Of the allocated memory 3.92 GiB is allocated by PyTorch, and 1.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 136, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1475, in relu
    result = torch.relu(input)
"
