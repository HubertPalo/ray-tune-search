trial_id,config,error_type,error_message,error_traceback
4fd40d6b,"{'enc_size': 77, 'ae_conv_num': 2, 'ae_conv_kernel': 4, 'ae_conv_stride': 1, 'ae_conv_padding': 1, 'ae_dropout': 0.49258288495453395, 'ae_fc_num': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 318.00 MiB (GPU 0; 23.65 GiB total capacity; 9.43 GiB already allocated; 279.94 MiB free; 9.80 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 93, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 58, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 127, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae_remade.py"", line 248, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae_remade.py"", line 111, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
b3949951,"{'enc_size': 24, 'ae_conv_num': 2, 'ae_conv_kernel': 4, 'ae_conv_stride': 1, 'ae_conv_padding': 1, 'ae_dropout': 0.13409892047294672, 'ae_fc_num': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 562.00 MiB (GPU 0; 23.65 GiB total capacity; 8.81 GiB already allocated; 479.94 MiB free; 10.60 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 93, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 58, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 127, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae_remade.py"", line 248, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae_remade.py"", line 111, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
f679a293,"{'enc_size': 39, 'ae_conv_num': 1, 'ae_conv_kernel': 3, 'ae_conv_stride': 1, 'ae_conv_padding': 1, 'ae_dropout': 0.2411966968023332, 'ae_fc_num': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 602.00 MiB (GPU 0; 23.65 GiB total capacity; 9.43 GiB already allocated; 159.94 MiB free; 10.92 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 93, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 58, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 127, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae_remade.py"", line 248, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae_remade.py"", line 111, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
4253dee4,"{'enc_size': 38, 'ae_conv_num': 3, 'ae_conv_kernel': 3, 'ae_conv_stride': 1, 'ae_conv_padding': 1, 'ae_dropout': 0.3457595342902371, 'ae_fc_num': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 340.00 MiB (GPU 0; 23.65 GiB total capacity; 9.50 GiB already allocated; 285.94 MiB free; 9.76 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 93, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 58, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 127, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae_remade.py"", line 248, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae_remade.py"", line 111, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
8692ff41,"{'enc_size': 17, 'ae_conv_num': 2, 'ae_conv_kernel': 4, 'ae_conv_stride': 1, 'ae_conv_padding': 0, 'ae_dropout': 0.4177358049577482, 'ae_fc_num': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 548.00 MiB (GPU 0; 23.65 GiB total capacity; 8.40 GiB already allocated; 287.94 MiB free; 9.76 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 93, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 58, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 127, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae_remade.py"", line 248, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae_remade.py"", line 111, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
d8571f3b,"{'enc_size': 75, 'ae_conv_num': 3, 'ae_conv_kernel': 2, 'ae_conv_stride': 1, 'ae_conv_padding': 0, 'ae_dropout': 0.4507247311771897, 'ae_fc_num': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 544.00 MiB (GPU 0; 23.65 GiB total capacity; 7.12 GiB already allocated; 519.94 MiB free; 9.53 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 93, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 58, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 127, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae_remade.py"", line 248, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae_remade.py"", line 111, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
9ce8ed5c,"{'enc_size': 42, 'ae_conv_num': 1, 'ae_conv_kernel': 2, 'ae_conv_stride': 1, 'ae_conv_padding': 1, 'ae_dropout': 0.4377635727146661, 'ae_fc_num': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 210.00 MiB (GPU 0; 23.65 GiB total capacity; 10.57 GiB already allocated; 27.94 MiB free; 11.16 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 93, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 58, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 127, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae_remade.py"", line 248, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae_remade.py"", line 111, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
82908e18,"{'enc_size': 31, 'ae_conv_num': 1, 'ae_conv_kernel': 3, 'ae_conv_stride': 1, 'ae_conv_padding': 1, 'ae_dropout': 0.4981753967976883, 'ae_fc_num': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 676.00 MiB (GPU 0; 23.65 GiB total capacity; 7.51 GiB already allocated; 39.94 MiB free; 9.18 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 93, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 58, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 127, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae_remade.py"", line 248, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae_remade.py"", line 111, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 92, in _init_group
    state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
6671d798,"{'enc_size': 15, 'ae_conv_num': 1, 'ae_conv_kernel': 4, 'ae_conv_stride': 1, 'ae_conv_padding': 1, 'ae_dropout': 0.37950008953708264, 'ae_fc_num': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 582.00 MiB (GPU 0; 23.65 GiB total capacity; 10.04 GiB already allocated; 51.94 MiB free; 11.15 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 93, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 58, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 127, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae_remade.py"", line 248, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae_remade.py"", line 111, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
332a6df7,"{'enc_size': 8, 'ae_conv_num': 1, 'ae_conv_kernel': 4, 'ae_conv_stride': 1, 'ae_conv_padding': 0, 'ae_dropout': 0.29855878412383935, 'ae_fc_num': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 610.00 MiB (GPU 0; 23.65 GiB total capacity; 7.96 GiB already allocated; 49.94 MiB free; 9.18 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 93, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 58, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 127, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae_remade.py"", line 248, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae_remade.py"", line 111, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
46db19ca,"{'enc_size': 26, 'ae_conv_num': 1, 'ae_conv_kernel': 3, 'ae_conv_stride': 1, 'ae_conv_padding': 0, 'ae_dropout': 0.41450380880816107, 'ae_fc_num': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 562.00 MiB (GPU 0; 23.65 GiB total capacity; 9.71 GiB already allocated; 37.94 MiB free; 11.15 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 93, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 58, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 127, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae_remade.py"", line 248, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae_remade.py"", line 111, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
593d288d,"{'enc_size': 27, 'ae_conv_num': 1, 'ae_conv_kernel': 4, 'ae_conv_stride': 1, 'ae_conv_padding': 0, 'ae_dropout': 0.4002959324857906, 'ae_fc_num': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 610.00 MiB (GPU 0; 23.65 GiB total capacity; 7.97 GiB already allocated; 47.94 MiB free; 9.18 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 93, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 58, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 127, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae_remade.py"", line 248, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae_remade.py"", line 111, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
9d17ce21,"{'enc_size': 28, 'ae_conv_num': 1, 'ae_conv_kernel': 3, 'ae_conv_stride': 1, 'ae_conv_padding': 0, 'ae_dropout': 0.4445869686935111, 'ae_fc_num': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 562.00 MiB (GPU 0; 23.65 GiB total capacity; 7.34 GiB already allocated; 45.94 MiB free; 9.18 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 93, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 58, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 127, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae_remade.py"", line 248, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae_remade.py"", line 111, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
6bb5d74b,"{'enc_size': 50, 'ae_conv_num': 1, 'ae_conv_kernel': 3, 'ae_conv_stride': 1, 'ae_conv_padding': 0, 'ae_dropout': 0.49934501657581354, 'ae_fc_num': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 632.00 MiB (GPU 0; 23.65 GiB total capacity; 8.26 GiB already allocated; 37.94 MiB free; 9.18 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 93, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 58, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 127, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae_remade.py"", line 248, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae_remade.py"", line 111, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
6acbe44d,"{'enc_size': 23, 'ae_conv_num': 1, 'ae_conv_kernel': 3, 'ae_conv_stride': 1, 'ae_conv_padding': 0, 'ae_dropout': 0.11031373767549324, 'ae_fc_num': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 562.00 MiB (GPU 0; 23.65 GiB total capacity; 7.33 GiB already allocated; 39.94 MiB free; 9.18 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 93, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 58, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 127, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae_remade.py"", line 248, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae_remade.py"", line 111, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
09ca906b,"{'enc_size': 49, 'ae_conv_num': 1, 'ae_conv_kernel': 3, 'ae_conv_stride': 1, 'ae_conv_padding': 1, 'ae_dropout': 0.37157380227114944, 'ae_fc_num': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 602.00 MiB (GPU 0; 23.65 GiB total capacity; 10.42 GiB already allocated; 69.94 MiB free; 11.16 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 93, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 58, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 127, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae_remade.py"", line 248, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae_remade.py"", line 111, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
1051f14c,"{'enc_size': 53, 'ae_conv_num': 1, 'ae_conv_kernel': 4, 'ae_conv_stride': 1, 'ae_conv_padding': 1, 'ae_dropout': 0.3809867499600112, 'ae_fc_num': 0, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",0 reducer,There is no reducer in the configuration.,There is no reducer in the configuration.
5878dfc7,"{'enc_size': 45, 'ae_conv_num': 1, 'ae_conv_kernel': 3, 'ae_conv_stride': 1, 'ae_conv_padding': 1, 'ae_dropout': 0.4108613386558976, 'ae_fc_num': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 676.00 MiB (GPU 0; 23.65 GiB total capacity; 12.59 GiB already allocated; 169.94 MiB free; 13.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 93, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 58, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 127, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae_remade.py"", line 248, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae_remade.py"", line 111, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
