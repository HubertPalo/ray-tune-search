trial_id,config,error_type,error_message,error_traceback
885b78be,"{'batch_size': 64, 'num_CL': 4, 'size_CL': 26, 'kernel': 4, 'num_HL': 4, 'latent_dim': 264, 'opt_lr': 0.00031564653529958053, 'opt_wd': 2.9879199797183076e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 238.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 16.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 739758 has 4.18 GiB memory in use. Process 743043 has 5.66 GiB memory in use. Of the allocated memory 5.32 GiB is allocated by PyTorch, and 68.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
9825d184,"{'batch_size': 64, 'num_CL': 3, 'size_CL': 27, 'kernel': 3, 'num_HL': 3, 'latent_dim': 140, 'opt_lr': 0.0002064395370135269, 'opt_wd': 8.08994470021994e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 236.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 108.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 739758 has 4.18 GiB memory in use. Process 743043 has 5.57 GiB memory in use. Of the allocated memory 4.73 GiB is allocated by PyTorch, and 577.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
ded2f90f,"{'batch_size': 128, 'num_CL': 3, 'size_CL': 29, 'kernel': 2, 'num_HL': 3, 'latent_dim': 207, 'opt_lr': 1.2859758507616956e-05, 'opt_wd': 1.4119845650555352e-08}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 276.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 250.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 739758 has 4.18 GiB memory in use. Process 743043 has 5.43 GiB memory in use. Of the allocated memory 4.87 GiB is allocated by PyTorch, and 294.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
5b8c674a,"{'batch_size': 128, 'num_CL': 2, 'size_CL': 25, 'kernel': 3, 'num_HL': 4, 'latent_dim': 68, 'opt_lr': 0.0002009206827636544, 'opt_wd': 2.967909913500339e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 228.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 18.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 739758 has 4.12 GiB memory in use. Process 743043 has 5.72 GiB memory in use. Of the allocated memory 5.01 GiB is allocated by PyTorch, and 442.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
09ab806a,"{'batch_size': 128, 'num_CL': 2, 'size_CL': 28, 'kernel': 4, 'num_HL': 4, 'latent_dim': 78, 'opt_lr': 3.8334626577873756e-05, 'opt_wd': 2.6201197070505553e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 70.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 739758 has 4.39 GiB memory in use. Process 743043 has 5.40 GiB memory in use. Of the allocated memory 4.91 GiB is allocated by PyTorch, and 213.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 506, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
b6f4d752,"{'batch_size': 64, 'num_CL': 3, 'size_CL': 31, 'kernel': 3, 'num_HL': 3, 'latent_dim': 116, 'opt_lr': 0.00040162338453661494, 'opt_wd': 9.01856322931679e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 308.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 132.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 739758 has 5.41 GiB memory in use. Process 743043 has 4.31 GiB memory in use. Of the allocated memory 4.87 GiB is allocated by PyTorch, and 271.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
77df1b78,"{'batch_size': 64, 'num_CL': 3, 'size_CL': 22, 'kernel': 3, 'num_HL': 3, 'latent_dim': 49, 'opt_lr': 4.6056701690628644e-05, 'opt_wd': 7.304506982266023e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 308.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 164.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 739758 has 5.44 GiB memory in use. Process 743043 has 4.26 GiB memory in use. Of the allocated memory 2.96 GiB is allocated by PyTorch, and 1.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 302, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 1475, in relu
    result = torch.relu(input)
"
35ff7c8e,"{'batch_size': 64, 'num_CL': 3, 'size_CL': 23, 'kernel': 4, 'num_HL': 3, 'latent_dim': 123, 'opt_lr': 1.9735300377800754e-05, 'opt_wd': 7.578743544582765e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 322.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 170.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 739758 has 5.44 GiB memory in use. Process 743043 has 4.25 GiB memory in use. Of the allocated memory 2.86 GiB is allocated by PyTorch, and 1.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 302, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 1475, in relu
    result = torch.relu(input)
"
41e53e3d,"{'batch_size': 64, 'num_CL': 3, 'size_CL': 27, 'kernel': 4, 'num_HL': 3, 'latent_dim': 109, 'opt_lr': 8.682549869121745e-05, 'opt_wd': 3.7277860048766856e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 230.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 194.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 739758 has 5.39 GiB memory in use. Process 743043 has 4.27 GiB memory in use. Of the allocated memory 3.64 GiB is allocated by PyTorch, and 1.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
95c66747,"{'batch_size': 64, 'num_CL': 2, 'size_CL': 30, 'kernel': 4, 'num_HL': 3, 'latent_dim': 230, 'opt_lr': 2.213458982617816e-05, 'opt_wd': 9.583166276580715e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 290.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 260.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 739758 has 5.31 GiB memory in use. Process 743043 has 4.29 GiB memory in use. Of the allocated memory 4.35 GiB is allocated by PyTorch, and 704.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 506, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
6b15e026,"{'batch_size': 64, 'num_CL': 4, 'size_CL': 25, 'kernel': 4, 'num_HL': 3, 'latent_dim': 269, 'opt_lr': 1.1932135581795049e-05, 'opt_wd': 9.867860376367799e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 344.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 148.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 739758 has 5.42 GiB memory in use. Process 743043 has 4.29 GiB memory in use. Of the allocated memory 4.00 GiB is allocated by PyTorch, and 1.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 302, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 1475, in relu
    result = torch.relu(input)
"
b8fc421f,"{'batch_size': 128, 'num_CL': 3, 'size_CL': 29, 'kernel': 4, 'num_HL': 4, 'latent_dim': 138, 'opt_lr': 1.1044608918746014e-05, 'opt_wd': 3.8008186559651654e-08}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 298.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 150.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 739758 has 5.42 GiB memory in use. Process 743043 has 4.29 GiB memory in use. Of the allocated memory 4.63 GiB is allocated by PyTorch, and 526.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 444, in _multi_tensor_adam
    device_grads = torch._foreach_add(device_grads, device_params, alpha=weight_decay)
"
eb1b91c3,"{'batch_size': 64, 'num_CL': 3, 'size_CL': 32, 'kernel': 4, 'num_HL': 3, 'latent_dim': 142, 'opt_lr': 5.9091847418139316e-05, 'opt_wd': 8.45787309608723e-07}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 120.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 739758 has 4.94 GiB memory in use. Process 743043 has 4.80 GiB memory in use. Of the allocated memory 4.27 GiB is allocated by PyTorch, and 259.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 506, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
9bf8ee02,"{'batch_size': 64, 'num_CL': 3, 'size_CL': 20, 'kernel': 2, 'num_HL': 4, 'latent_dim': 155, 'opt_lr': 0.00011917015117479027, 'opt_wd': 2.447749828888491e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 112.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 739758 has 4.94 GiB memory in use. Process 743043 has 4.81 GiB memory in use. Of the allocated memory 3.51 GiB is allocated by PyTorch, and 1.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 302, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 1475, in relu
    result = torch.relu(input)
"
95f481bd,"{'batch_size': 64, 'num_CL': 2, 'size_CL': 27, 'kernel': 3, 'num_HL': 3, 'latent_dim': 89, 'opt_lr': 6.848851166106455e-05, 'opt_wd': 9.987161609532014e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 238.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 54.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 739758 has 4.94 GiB memory in use. Process 743043 has 4.86 GiB memory in use. Of the allocated memory 4.13 GiB is allocated by PyTorch, and 470.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
6da256cd,"{'batch_size': 64, 'num_CL': 3, 'size_CL': 28, 'kernel': 4, 'num_HL': 3, 'latent_dim': 148, 'opt_lr': 0.00010219435365277595, 'opt_wd': 1.5278475328081284e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 248.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 54.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 739758 has 4.94 GiB memory in use. Process 743043 has 4.86 GiB memory in use. Of the allocated memory 3.69 GiB is allocated by PyTorch, and 914.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 506, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
e6564bac,"{'batch_size': 128, 'num_CL': 3, 'size_CL': 24, 'kernel': 4, 'num_HL': 3, 'latent_dim': 205, 'opt_lr': 7.59241808909178e-05, 'opt_wd': 9.35675052338475e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 56.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 739758 has 4.94 GiB memory in use. Process 743043 has 4.86 GiB memory in use. Of the allocated memory 3.24 GiB is allocated by PyTorch, and 1.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
f2e415c1,"{'batch_size': 64, 'num_CL': 3, 'size_CL': 31, 'kernel': 4, 'num_HL': 4, 'latent_dim': 187, 'opt_lr': 2.3492739696365084e-05, 'opt_wd': 1.2076548587371832e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 342.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 190.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 739758 has 4.77 GiB memory in use. Process 743043 has 4.90 GiB memory in use. Of the allocated memory 4.19 GiB is allocated by PyTorch, and 314.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 134, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 96, in _init_group
    state['exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
f8b2a84d,"{'batch_size': 128, 'num_CL': 3, 'size_CL': 26, 'kernel': 4, 'num_HL': 4, 'latent_dim': 72, 'opt_lr': 1.0047092614994415e-05, 'opt_wd': 7.188633466790744e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 240.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 184.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 739758 has 4.78 GiB memory in use. Process 743043 has 4.90 GiB memory in use. Of the allocated memory 3.70 GiB is allocated by PyTorch, and 824.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 444, in _multi_tensor_adam
    device_grads = torch._foreach_add(device_grads, device_params, alpha=weight_decay)
"
2ee60322,"{'batch_size': 64, 'num_CL': 3, 'size_CL': 25, 'kernel': 4, 'num_HL': 3, 'latent_dim': 152, 'opt_lr': 6.285684323032156e-05, 'opt_wd': 3.920570078461005e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 234.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 2.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 739758 has 4.96 GiB memory in use. Process 743043 has 4.90 GiB memory in use. Of the allocated memory 3.89 GiB is allocated by PyTorch, and 806.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 302, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 1475, in relu
    result = torch.relu(input)
"
66af33aa,"{'batch_size': 128, 'num_CL': 4, 'size_CL': 30, 'kernel': 3, 'num_HL': 2, 'latent_dim': 148, 'opt_lr': 2.187155625033791e-05, 'opt_wd': 6.492348826135596e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 110.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 739758 has 3.31 GiB memory in use. Process 743043 has 6.44 GiB memory in use. Of the allocated memory 3.01 GiB is allocated by PyTorch, and 20.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
cbf6587d,"{'batch_size': 64, 'num_CL': 3, 'size_CL': 21, 'kernel': 4, 'num_HL': 3, 'latent_dim': 123, 'opt_lr': 3.066434890910632e-05, 'opt_wd': 6.970236370489042e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 140.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 106.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 739758 has 3.31 GiB memory in use. Process 743043 has 6.45 GiB memory in use. Of the allocated memory 2.46 GiB is allocated by PyTorch, and 584.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
0372e949,"{'batch_size': 64, 'num_CL': 3, 'size_CL': 29, 'kernel': 4, 'num_HL': 4, 'latent_dim': 79, 'opt_lr': 2.8183370013550724e-05, 'opt_wd': 5.726015052869645e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 150.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 52.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 739758 has 3.36 GiB memory in use. Process 743043 has 6.45 GiB memory in use. Of the allocated memory 3.05 GiB is allocated by PyTorch, and 37.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 134, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 94, in _init_group
    state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
29c170e7,"{'batch_size': 64, 'num_CL': 3, 'size_CL': 22, 'kernel': 2, 'num_HL': 3, 'latent_dim': 169, 'opt_lr': 1.7445879292667774e-05, 'opt_wd': 1.372293511424626e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 160.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 142.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 739758 has 3.27 GiB memory in use. Process 743043 has 6.45 GiB memory in use. Of the allocated memory 2.81 GiB is allocated by PyTorch, and 188.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
34186de8,"{'batch_size': 64, 'num_CL': 3, 'size_CL': 31, 'kernel': 4, 'num_HL': 3, 'latent_dim': 89, 'opt_lr': 8.652834756631012e-05, 'opt_wd': 7.54360109075483e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 304.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 200.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 739758 has 3.21 GiB memory in use. Process 743043 has 6.45 GiB memory in use. Of the allocated memory 2.90 GiB is allocated by PyTorch, and 42.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 134, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 96, in _init_group
    state['exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
2fdcfc08,"{'batch_size': 64, 'num_CL': 2, 'size_CL': 20, 'kernel': 4, 'num_HL': 4, 'latent_dim': 146, 'opt_lr': 0.00014558927293263087, 'opt_wd': 9.569813434500204e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 146.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 54.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 739758 has 3.36 GiB memory in use. Process 743043 has 6.45 GiB memory in use. Of the allocated memory 2.89 GiB is allocated by PyTorch, and 194.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
cb72c652,"{'batch_size': 128, 'num_CL': 4, 'size_CL': 19, 'kernel': 3, 'num_HL': 3, 'latent_dim': 154, 'opt_lr': 2.740067785762193e-05, 'opt_wd': 7.112994840800793e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 268.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 252.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 739758 has 3.16 GiB memory in use. Process 743043 has 6.45 GiB memory in use. Of the allocated memory 2.08 GiB is allocated by PyTorch, and 822.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 302, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 1475, in relu
    result = torch.relu(input)
"
3dac1cfb,"{'batch_size': 64, 'num_CL': 3, 'size_CL': 27, 'kernel': 4, 'num_HL': 4, 'latent_dim': 195, 'opt_lr': 1.4322301930297241e-05, 'opt_wd': 6.221210566529255e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 134.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 86.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 739758 has 3.32 GiB memory in use. Process 743043 has 6.45 GiB memory in use. Of the allocated memory 2.68 GiB is allocated by PyTorch, and 373.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 134, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 94, in _init_group
    state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
789421dc,"{'batch_size': 64, 'num_CL': 3, 'size_CL': 23, 'kernel': 3, 'num_HL': 3, 'latent_dim': 83, 'opt_lr': 3.1767475970511766e-05, 'opt_wd': 7.515254304477806e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 170.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 168.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 739758 has 3.24 GiB memory in use. Process 743043 has 6.45 GiB memory in use. Of the allocated memory 2.24 GiB is allocated by PyTorch, and 742.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 506, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
bfd9c2b9,"{'batch_size': 64, 'num_CL': 3, 'size_CL': 25, 'kernel': 4, 'num_HL': 4, 'latent_dim': 75, 'opt_lr': 1.871961611806208e-05, 'opt_wd': 6.53997787285956e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 172.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 739758 has 3.24 GiB memory in use. Process 743043 has 6.45 GiB memory in use. Of the allocated memory 2.48 GiB is allocated by PyTorch, and 493.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 119, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 134, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 94, in _init_group
    state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
