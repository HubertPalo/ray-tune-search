trial_id,config,error_type,error_message,error_traceback
44e63f0a,"{'batch_size': 64, 'num_HL': 5, 'latent_dim': 15, 'num_CL': 4, 'size_CL': 28, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 298.00 MiB (GPU 0; 23.65 GiB total capacity; 6.69 GiB already allocated; 97.94 MiB free; 7.12 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
bedbd95f,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 10, 'num_CL': 4, 'size_CL': 30, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 284.00 MiB (GPU 0; 23.65 GiB total capacity; 2.42 GiB already allocated; 19.94 MiB free; 2.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 92, in _init_group
    state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
2c0d798e,"{'batch_size': 128, 'num_HL': 7, 'latent_dim': 11, 'num_CL': 3, 'size_CL': 16, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 108.00 MiB (GPU 0; 23.65 GiB total capacity; 2.80 GiB already allocated; 11.94 MiB free; 3.03 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
ea426df8,"{'batch_size': 64, 'num_HL': 6, 'latent_dim': 9, 'num_CL': 3, 'size_CL': 25, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 170.00 MiB (GPU 0; 23.65 GiB total capacity; 6.05 GiB already allocated; 75.94 MiB free; 6.23 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
47f70ae4,"{'batch_size': 128, 'num_HL': 5, 'latent_dim': 11, 'num_CL': 3, 'size_CL': 20, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 156.00 MiB (GPU 0; 23.65 GiB total capacity; 3.52 GiB already allocated; 135.94 MiB free; 4.42 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
ba5a922d,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 13, 'num_CL': 4, 'size_CL': 32, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 316.00 MiB (GPU 0; 23.65 GiB total capacity; 3.31 GiB already allocated; 247.94 MiB free; 3.47 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
30829078,"{'batch_size': 128, 'num_HL': 7, 'latent_dim': 2, 'num_CL': 2, 'size_CL': 23, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 222.00 MiB (GPU 0; 23.65 GiB total capacity; 1.24 GiB already allocated; 43.94 MiB free; 1.26 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
15603cba,"{'batch_size': 64, 'num_HL': 4, 'latent_dim': 18, 'num_CL': 3, 'size_CL': 9, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 23.65 GiB total capacity; 1.26 GiB already allocated; 11.94 MiB free; 1.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
d1c07df6,"{'batch_size': 128, 'num_HL': 5, 'latent_dim': 5, 'num_CL': 4, 'size_CL': 31, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 356.00 MiB (GPU 0; 23.65 GiB total capacity; 1.23 GiB already allocated; 41.94 MiB free; 1.26 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
8c278139,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 16, 'num_CL': 3, 'size_CL': 3, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.65 GiB total capacity; 1.26 GiB already allocated; 11.94 MiB free; 1.28 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
ae81e822,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 12, 'num_CL': 3, 'size_CL': 8, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.65 GiB total capacity; 1.25 GiB already allocated; 11.94 MiB free; 1.28 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
fcd8c8f8,"{'batch_size': 64, 'num_HL': 8, 'latent_dim': 14, 'num_CL': 3, 'size_CL': 7, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 23.65 GiB total capacity; 1.16 GiB already allocated; 45.94 MiB free; 1.38 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
09e45da3,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 17, 'num_CL': 3, 'size_CL': 19, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 88.00 MiB (GPU 0; 23.65 GiB total capacity; 1.03 GiB already allocated; 81.94 MiB free; 1.34 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
6e4f8325,"{'batch_size': 128, 'num_HL': 6, 'latent_dim': 3, 'num_CL': 3, 'size_CL': 29, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 132.00 MiB (GPU 0; 23.65 GiB total capacity; 9.87 GiB already allocated; 103.94 MiB free; 10.44 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
37ab4264,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 15, 'num_CL': 4, 'size_CL': 20, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 298.00 MiB (GPU 0; 23.65 GiB total capacity; 1.85 GiB already allocated; 263.94 MiB free; 2.47 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
67883d15,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 14, 'num_CL': 3, 'size_CL': 17, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 250.00 MiB (GPU 0; 23.65 GiB total capacity; 1.95 GiB already allocated; 15.94 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
62fd6ee3,"{'batch_size': 128, 'num_HL': 4, 'latent_dim': 18, 'num_CL': 2, 'size_CL': 18, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 118.00 MiB (GPU 0; 23.65 GiB total capacity; 2.59 GiB already allocated; 15.94 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
5848fd13,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 16, 'num_CL': 4, 'size_CL': 26, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 210.00 MiB (GPU 0; 23.65 GiB total capacity; 2.53 GiB already allocated; 53.94 MiB free; 2.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
0d2dac9a,"{'batch_size': 128, 'num_HL': 7, 'latent_dim': 11, 'num_CL': 3, 'size_CL': 15, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 14.00 MiB (GPU 0; 23.65 GiB total capacity; 2.67 GiB already allocated; 7.94 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
4bbdc2bd,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 15, 'num_CL': 3, 'size_CL': 13, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 194.00 MiB (GPU 0; 23.65 GiB total capacity; 944.84 MiB already allocated; 165.94 MiB free; 1012.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
99954aa2,"{'batch_size': 64, 'num_HL': 5, 'latent_dim': 13, 'num_CL': 3, 'size_CL': 24, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 132.00 MiB (GPU 0; 23.65 GiB total capacity; 1.11 GiB already allocated; 35.94 MiB free; 1.12 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
0e516ae0,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 11, 'num_CL': 3, 'size_CL': 19, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 114.00 MiB (GPU 0; 23.65 GiB total capacity; 747.82 MiB already allocated; 85.94 MiB free; 1.07 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
8152ef54,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 12, 'num_CL': 4, 'size_CL': 27, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 170.00 MiB (GPU 0; 23.65 GiB total capacity; 872.86 MiB already allocated; 141.94 MiB free; 1.01 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
252b7439,"{'batch_size': 128, 'num_HL': 4, 'latent_dim': 9, 'num_CL': 3, 'size_CL': 23, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 94.00 MiB (GPU 0; 23.65 GiB total capacity; 1021.28 MiB already allocated; 43.94 MiB free; 1.11 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
196e6d8c,"{'batch_size': 64, 'num_HL': 6, 'latent_dim': 8, 'num_CL': 3, 'size_CL': 21, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 174.00 MiB (GPU 0; 23.65 GiB total capacity; 2.83 GiB already allocated; 89.94 MiB free; 3.30 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 92, in _init_group
    state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
848d2001,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 14, 'num_CL': 3, 'size_CL': 30, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 212.00 MiB (GPU 0; 23.65 GiB total capacity; 1.07 GiB already allocated; 101.94 MiB free; 1.10 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
ef155160,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 13, 'num_CL': 3, 'size_CL': 18, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 78.00 MiB (GPU 0; 23.65 GiB total capacity; 858.08 MiB already allocated; 17.94 MiB free; 1.17 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
3c1eddbb,"{'batch_size': 128, 'num_HL': 4, 'latent_dim': 13, 'num_CL': 4, 'size_CL': 22, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 168.00 MiB (GPU 0; 23.65 GiB total capacity; 1013.76 MiB already allocated; 17.94 MiB free; 1.17 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
c2473a33,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 14, 'num_CL': 3, 'size_CL': 17, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 92.00 MiB (GPU 0; 23.65 GiB total capacity; 1.11 GiB already allocated; 15.94 MiB free; 1.17 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
7b22d915,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 12, 'num_CL': 3, 'size_CL': 25, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 372.00 MiB (GPU 0; 23.65 GiB total capacity; 1.84 GiB already allocated; 89.94 MiB free; 2.01 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
812a08fa,"{'batch_size': 128, 'num_HL': 5, 'latent_dim': 15, 'num_CL': 3, 'size_CL': 24, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 132.00 MiB (GPU 0; 23.65 GiB total capacity; 1.86 GiB already allocated; 125.94 MiB free; 1.97 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
6894a268,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 12, 'num_CL': 4, 'size_CL': 26, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 158.00 MiB (GPU 0; 23.65 GiB total capacity; 1.70 GiB already allocated; 123.94 MiB free; 1.97 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
f0451cf6,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 15, 'num_CL': 3, 'size_CL': 27, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 230.00 MiB (GPU 0; 23.65 GiB total capacity; 1.95 GiB already allocated; 27.94 MiB free; 2.07 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 92, in _init_group
    state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
6bbd69e5,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 10, 'num_CL': 3, 'size_CL': 20, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 294.00 MiB (GPU 0; 23.65 GiB total capacity; 2.53 GiB already allocated; 183.94 MiB free; 3.15 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
2eedc829,"{'batch_size': 64, 'num_HL': 4, 'latent_dim': 16, 'num_CL': 3, 'size_CL': 29, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 150.00 MiB (GPU 0; 23.65 GiB total capacity; 2.11 GiB already allocated; 21.94 MiB free; 2.23 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
c597c0a7,"{'batch_size': 128, 'num_HL': 8, 'latent_dim': 14, 'num_CL': 3, 'size_CL': 25, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 258.00 MiB (GPU 0; 23.65 GiB total capacity; 2.83 GiB already allocated; 49.94 MiB free; 3.12 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
77390ee5,"{'batch_size': 64, 'num_HL': 7, 'latent_dim': 13, 'num_CL': 3, 'size_CL': 28, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 316.00 MiB (GPU 0; 23.65 GiB total capacity; 3.04 GiB already allocated; 111.94 MiB free; 3.05 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
09053c92,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 12, 'num_CL': 4, 'size_CL': 15, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 220.00 MiB (GPU 0; 23.65 GiB total capacity; 1.58 GiB already allocated; 115.94 MiB free; 2.23 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
65bc40af,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 11, 'num_CL': 3, 'size_CL': 16, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 238.00 MiB (GPU 0; 23.65 GiB total capacity; 873.60 MiB already allocated; 95.94 MiB free; 1.19 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
0272d9f3,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 17, 'num_CL': 3, 'size_CL': 19, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 86.00 MiB (GPU 0; 23.65 GiB total capacity; 1.02 GiB already allocated; 65.94 MiB free; 1.22 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
3165b4f1,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 15, 'num_CL': 3, 'size_CL': 21, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 104.00 MiB (GPU 0; 23.65 GiB total capacity; 1.14 GiB already allocated; 99.94 MiB free; 1.19 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
c3c87cb3,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 16, 'num_CL': 3, 'size_CL': 20, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 23.65 GiB total capacity; 1.12 GiB already allocated; 37.94 MiB free; 1.25 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
ffeff2f1,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 16, 'num_CL': 3, 'size_CL': 24, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 354.00 MiB (GPU 0; 23.65 GiB total capacity; 2.05 GiB already allocated; 259.94 MiB free; 2.34 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
2100a23c,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 17, 'num_CL': 3, 'size_CL': 11, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 162.00 MiB (GPU 0; 23.65 GiB total capacity; 1.00 GiB already allocated; 107.94 MiB free; 1.41 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
ef68e6ac,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 14, 'num_CL': 3, 'size_CL': 32, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 242.00 MiB (GPU 0; 23.65 GiB total capacity; 1.43 GiB already allocated; 53.94 MiB free; 1.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 92, in _init_group
    state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
504308e1,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 16, 'num_CL': 3, 'size_CL': 18, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 264.00 MiB (GPU 0; 23.65 GiB total capacity; 1.56 GiB already allocated; 37.94 MiB free; 2.23 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
dfc9519e,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 15, 'num_CL': 3, 'size_CL': 23, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 344.00 MiB (GPU 0; 23.65 GiB total capacity; 1.58 GiB already allocated; 33.94 MiB free; 2.34 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
c4285c5e,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 17, 'num_CL': 3, 'size_CL': 14, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 210.00 MiB (GPU 0; 23.65 GiB total capacity; 1.04 GiB already allocated; 45.94 MiB free; 1.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
e6cca5b5,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 18, 'num_CL': 3, 'size_CL': 19, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 38.00 MiB (GPU 0; 23.65 GiB total capacity; 1.35 GiB already allocated; 33.94 MiB free; 1.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
eca8277f,"{'batch_size': 128, 'num_HL': 4, 'latent_dim': 14, 'num_CL': 3, 'size_CL': 18, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 116.00 MiB (GPU 0; 23.65 GiB total capacity; 1.28 GiB already allocated; 33.94 MiB free; 1.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 92, in _init_group
    state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
aa994c28,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 13, 'num_CL': 3, 'size_CL': 23, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 166.00 MiB (GPU 0; 23.65 GiB total capacity; 1.06 GiB already allocated; 35.94 MiB free; 1.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
49d73b78,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 9, 'num_CL': 3, 'size_CL': 20, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 126.00 MiB (GPU 0; 23.65 GiB total capacity; 1.08 GiB already allocated; 33.94 MiB free; 1.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 92, in _init_group
    state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
71b03340,"{'batch_size': 128, 'num_HL': 4, 'latent_dim': 15, 'num_CL': 3, 'size_CL': 16, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 92.00 MiB (GPU 0; 23.65 GiB total capacity; 1.40 GiB already allocated; 31.94 MiB free; 1.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
1d39a501,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 18, 'num_CL': 3, 'size_CL': 25, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 198.00 MiB (GPU 0; 23.65 GiB total capacity; 1.06 GiB already allocated; 33.94 MiB free; 1.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
c9524e92,"{'batch_size': 64, 'num_HL': 5, 'latent_dim': 16, 'num_CL': 3, 'size_CL': 14, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 74.00 MiB (GPU 0; 23.65 GiB total capacity; 1.39 GiB already allocated; 31.94 MiB free; 1.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
dc0e7a90,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 10, 'num_CL': 3, 'size_CL': 15, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 23.65 GiB total capacity; 1.15 GiB already allocated; 33.94 MiB free; 1.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
547de1df,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 17, 'num_CL': 3, 'size_CL': 21, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 140.00 MiB (GPU 0; 23.65 GiB total capacity; 1.19 GiB already allocated; 33.94 MiB free; 1.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 92, in _init_group
    state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
cca0cf27,"{'batch_size': 128, 'num_HL': 4, 'latent_dim': 11, 'num_CL': 3, 'size_CL': 13, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 23.65 GiB total capacity; 1.57 GiB already allocated; 47.94 MiB free; 2.23 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
d6313bbd,"{'batch_size': 128, 'num_HL': 4, 'latent_dim': 14, 'num_CL': 3, 'size_CL': 17, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 102.00 MiB (GPU 0; 23.65 GiB total capacity; 1.35 GiB already allocated; 47.94 MiB free; 1.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
3837e109,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 11, 'num_CL': 2, 'size_CL': 19, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 116.00 MiB (GPU 0; 23.65 GiB total capacity; 1.41 GiB already allocated; 5.94 MiB free; 1.50 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
77262279,"{'batch_size': 128, 'num_HL': 5, 'latent_dim': 17, 'num_CL': 3, 'size_CL': 22, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 184.00 MiB (GPU 0; 23.65 GiB total capacity; 4.83 GiB already allocated; 71.94 MiB free; 5.42 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
e55cd692,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 15, 'num_CL': 3, 'size_CL': 17, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 252.00 MiB (GPU 0; 23.65 GiB total capacity; 1.71 GiB already allocated; 79.94 MiB free; 2.34 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
8311f405,"{'batch_size': 64, 'num_HL': 6, 'latent_dim': 15, 'num_CL': 2, 'size_CL': 20, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 160.00 MiB (GPU 0; 23.65 GiB total capacity; 4.96 GiB already allocated; 71.94 MiB free; 5.42 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
ca614fc1,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 13, 'num_CL': 3, 'size_CL': 10, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 150.00 MiB (GPU 0; 23.65 GiB total capacity; 417.37 MiB already allocated; 5.94 MiB free; 548.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
20594a7f,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 12, 'num_CL': 3, 'size_CL': 18, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 23.65 GiB total capacity; 2.24 GiB already allocated; 141.94 MiB free; 2.41 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
c241ce44,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 18, 'num_CL': 3, 'size_CL': 13, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 40.00 MiB (GPU 0; 23.65 GiB total capacity; 457.57 MiB already allocated; 5.94 MiB free; 548.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
85e279f7,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 16, 'num_CL': 3, 'size_CL': 14, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 210.00 MiB (GPU 0; 23.65 GiB total capacity; 703.32 MiB already allocated; 131.94 MiB free; 806.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
e2e3a635,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 11, 'num_CL': 3, 'size_CL': 11, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 164.00 MiB (GPU 0; 23.65 GiB total capacity; 703.34 MiB already allocated; 137.94 MiB free; 786.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
cdf3fd3c,"{'batch_size': 64, 'num_HL': 4, 'latent_dim': 6, 'num_CL': 3, 'size_CL': 21, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 78.00 MiB (GPU 0; 23.65 GiB total capacity; 840.97 MiB already allocated; 33.94 MiB free; 890.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
de12c02e,"{'batch_size': 128, 'num_HL': 7, 'latent_dim': 9, 'num_CL': 2, 'size_CL': 9, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 34.00 MiB (GPU 0; 23.65 GiB total capacity; 876.35 MiB already allocated; 11.94 MiB free; 912.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
720c76f2,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 18, 'num_CL': 3, 'size_CL': 24, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 136.00 MiB (GPU 0; 23.65 GiB total capacity; 714.03 MiB already allocated; 127.94 MiB free; 796.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
4c9d3865,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 17, 'num_CL': 3, 'size_CL': 29, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 264.00 MiB (GPU 0; 23.65 GiB total capacity; 749.30 MiB already allocated; 165.94 MiB free; 758.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
6756e47d,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 15, 'num_CL': 3, 'size_CL': 15, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 222.00 MiB (GPU 0; 23.65 GiB total capacity; 1.39 GiB already allocated; 175.94 MiB free; 2.16 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
e273399c,"{'batch_size': 128, 'num_HL': 5, 'latent_dim': 12, 'num_CL': 4, 'size_CL': 26, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 250.00 MiB (GPU 0; 23.65 GiB total capacity; 767.37 MiB already allocated; 27.94 MiB free; 906.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
f35f873a,"{'batch_size': 64, 'num_HL': 4, 'latent_dim': 14, 'num_CL': 3, 'size_CL': 31, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 340.00 MiB (GPU 0; 23.65 GiB total capacity; 809.08 MiB already allocated; 85.94 MiB free; 842.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
558f6445,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 16, 'num_CL': 4, 'size_CL': 20, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 94.00 MiB (GPU 0; 23.65 GiB total capacity; 666.85 MiB already allocated; 9.94 MiB free; 916.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 94, in _init_group
    state['exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
be464764,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 11, 'num_CL': 3, 'size_CL': 23, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 166.00 MiB (GPU 0; 23.65 GiB total capacity; 773.05 MiB already allocated; 11.94 MiB free; 914.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
16c47481,"{'batch_size': 64, 'num_HL': 6, 'latent_dim': 18, 'num_CL': 3, 'size_CL': 25, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 246.00 MiB (GPU 0; 23.65 GiB total capacity; 5.37 GiB already allocated; 43.94 MiB free; 5.70 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
7adab7e1,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 16, 'num_CL': 2, 'size_CL': 27, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 78.00 MiB (GPU 0; 23.65 GiB total capacity; 1.31 GiB already allocated; 11.94 MiB free; 1.34 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
29a6fc3f,"{'batch_size': 128, 'num_HL': 4, 'latent_dim': 8, 'num_CL': 3, 'size_CL': 21, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 156.00 MiB (GPU 0; 23.65 GiB total capacity; 1.05 GiB already allocated; 11.94 MiB free; 1.34 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
3aa3e1f0,"{'batch_size': 128, 'num_HL': 4, 'latent_dim': 15, 'num_CL': 3, 'size_CL': 16, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 238.00 MiB (GPU 0; 23.65 GiB total capacity; 1.74 GiB already allocated; 37.94 MiB free; 2.35 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
e61cc769,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 12, 'num_CL': 3, 'size_CL': 15, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 222.00 MiB (GPU 0; 23.65 GiB total capacity; 1007.79 MiB already allocated; 65.94 MiB free; 1.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
40f95ba4,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 12, 'num_CL': 4, 'size_CL': 30, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 278.00 MiB (GPU 0; 23.65 GiB total capacity; 1.25 GiB already allocated; 89.94 MiB free; 1.27 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
787cb8b3,"{'batch_size': 128, 'num_HL': 8, 'latent_dim': 10, 'num_CL': 3, 'size_CL': 9, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 23.65 GiB total capacity; 1.32 GiB already allocated; 11.94 MiB free; 1.35 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
9a85b7fd,"{'batch_size': 64, 'num_HL': 4, 'latent_dim': 16, 'num_CL': 3, 'size_CL': 11, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 82.00 MiB (GPU 0; 23.65 GiB total capacity; 1.40 GiB already allocated; 49.94 MiB free; 1.60 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
a37d6b80,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 15, 'num_CL': 3, 'size_CL': 19, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 278.00 MiB (GPU 0; 23.65 GiB total capacity; 1.68 GiB already allocated; 181.94 MiB free; 2.21 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
9df58d5e,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 16, 'num_CL': 3, 'size_CL': 13, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 23.65 GiB total capacity; 817.22 MiB already allocated; 103.94 MiB free; 1.11 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
c1cb2fa5,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 18, 'num_CL': 3, 'size_CL': 12, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 176.00 MiB (GPU 0; 23.65 GiB total capacity; 903.64 MiB already allocated; 19.94 MiB free; 1.13 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
5123046a,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 9, 'num_CL': 3, 'size_CL': 13, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 23.65 GiB total capacity; 929.98 MiB already allocated; 17.94 MiB free; 1.13 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
e879d545,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 15, 'num_CL': 3, 'size_CL': 14, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 210.00 MiB (GPU 0; 23.65 GiB total capacity; 703.03 MiB already allocated; 197.94 MiB free; 982.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
0a2d90b7,"{'batch_size': 128, 'num_HL': 6, 'latent_dim': 16, 'num_CL': 3, 'size_CL': 10, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 40.00 MiB (GPU 0; 23.65 GiB total capacity; 1.06 GiB already allocated; 15.94 MiB free; 1.14 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
7565c189,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 17, 'num_CL': 2, 'size_CL': 15, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 23.65 GiB total capacity; 977.33 MiB already allocated; 35.94 MiB free; 1.12 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
e10fcfcf,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 14, 'num_CL': 3, 'size_CL': 17, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 250.00 MiB (GPU 0; 23.65 GiB total capacity; 1.43 GiB already allocated; 47.94 MiB free; 1.83 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
3c0a4613,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 15, 'num_CL': 3, 'size_CL': 5, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 23.65 GiB total capacity; 1.09 GiB already allocated; 11.94 MiB free; 1.14 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
30c02963,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 13, 'num_CL': 3, 'size_CL': 16, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 82.00 MiB (GPU 0; 23.65 GiB total capacity; 977.33 MiB already allocated; 37.94 MiB free; 1.12 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
72cbe0da,"{'batch_size': 128, 'num_HL': 5, 'latent_dim': 18, 'num_CL': 3, 'size_CL': 12, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 23.65 GiB total capacity; 1.04 GiB already allocated; 3.94 MiB free; 1.15 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
fd5475bb,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 17, 'num_CL': 2, 'size_CL': 23, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 23.65 GiB total capacity; 977.33 MiB already allocated; 37.94 MiB free; 1.12 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
460857b9,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 8, 'num_CL': 3, 'size_CL': 22, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 152.00 MiB (GPU 0; 23.65 GiB total capacity; 994.60 MiB already allocated; 93.94 MiB free; 1.06 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
121e6ee9,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 16, 'num_CL': 3, 'size_CL': 18, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 270.00 MiB (GPU 0; 23.65 GiB total capacity; 1.94 GiB already allocated; 109.94 MiB free; 1.98 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
793d3862,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 7, 'num_CL': 3, 'size_CL': 15, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 224.00 MiB (GPU 0; 23.65 GiB total capacity; 1.18 GiB already allocated; 139.94 MiB free; 1.81 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
7f58cffa,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 18, 'num_CL': 4, 'size_CL': 24, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 60.00 MiB (GPU 0; 23.65 GiB total capacity; 1.47 GiB already allocated; 37.94 MiB free; 1.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 94, in _init_group
    state['exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
2612cadf,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 14, 'num_CL': 3, 'size_CL': 20, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 296.00 MiB (GPU 0; 23.65 GiB total capacity; 1.53 GiB already allocated; 81.94 MiB free; 2.04 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
801edd0b,"{'batch_size': 128, 'num_HL': 7, 'latent_dim': 6, 'num_CL': 2, 'size_CL': 19, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 282.00 MiB (GPU 0; 23.65 GiB total capacity; 4.44 GiB already allocated; 83.94 MiB free; 5.70 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
b2ce2ef8,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 17, 'num_CL': 3, 'size_CL': 18, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 102.00 MiB (GPU 0; 23.65 GiB total capacity; 1.51 GiB already allocated; 53.94 MiB free; 1.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
cb4ffbe5,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 18, 'num_CL': 4, 'size_CL': 27, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 226.00 MiB (GPU 0; 23.65 GiB total capacity; 1.43 GiB already allocated; 97.94 MiB free; 1.59 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
dbed0709,"{'batch_size': 128, 'num_HL': 5, 'latent_dim': 13, 'num_CL': 3, 'size_CL': 9, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 134.00 MiB (GPU 0; 23.65 GiB total capacity; 910.48 MiB already allocated; 91.94 MiB free; 1.27 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
0a372eab,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 15, 'num_CL': 3, 'size_CL': 31, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 228.00 MiB (GPU 0; 23.65 GiB total capacity; 1.13 GiB already allocated; 199.94 MiB free; 1.16 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
de306685,"{'batch_size': 64, 'num_HL': 4, 'latent_dim': 14, 'num_CL': 3, 'size_CL': 25, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 222.00 MiB (GPU 0; 23.65 GiB total capacity; 1.68 GiB already allocated; 177.94 MiB free; 2.06 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
ac41104c,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 14, 'num_CL': 3, 'size_CL': 22, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 152.00 MiB (GPU 0; 23.65 GiB total capacity; 1.85 GiB already allocated; 25.94 MiB free; 2.21 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
c75b406b,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 13, 'num_CL': 3, 'size_CL': 19, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 86.00 MiB (GPU 0; 23.65 GiB total capacity; 868.46 MiB already allocated; 25.94 MiB free; 1.16 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
1f685fa5,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 2, 'num_CL': 3, 'size_CL': 26, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 212.00 MiB (GPU 0; 23.65 GiB total capacity; 954.50 MiB already allocated; 27.94 MiB free; 1.16 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
2de10721,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 13, 'num_CL': 3, 'size_CL': 20, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 296.00 MiB (GPU 0; 23.65 GiB total capacity; 1.53 GiB already allocated; 267.94 MiB free; 1.97 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
8241645c,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 16, 'num_CL': 3, 'size_CL': 18, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 23.65 GiB total capacity; 1.04 GiB already allocated; 171.94 MiB free; 1.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
3b646f32,"{'batch_size': 128, 'num_HL': 4, 'latent_dim': 16, 'num_CL': 3, 'size_CL': 28, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 194.00 MiB (GPU 0; 23.65 GiB total capacity; 6.16 GiB already allocated; 77.94 MiB free; 7.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
07cba4a0,"{'batch_size': 128, 'num_HL': 6, 'latent_dim': 13, 'num_CL': 3, 'size_CL': 21, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 174.00 MiB (GPU 0; 23.65 GiB total capacity; 3.79 GiB already allocated; 111.94 MiB free; 4.20 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
b678247e,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 14, 'num_CL': 3, 'size_CL': 19, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 278.00 MiB (GPU 0; 23.65 GiB total capacity; 2.33 GiB already allocated; 103.94 MiB free; 3.05 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
a8b68e3d,"{'batch_size': 64, 'num_HL': 4, 'latent_dim': 15, 'num_CL': 3, 'size_CL': 22, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 86.00 MiB (GPU 0; 23.65 GiB total capacity; 3.11 GiB already allocated; 23.94 MiB free; 3.31 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
be6d3b3e,"{'batch_size': 128, 'num_HL': 5, 'latent_dim': 16, 'num_CL': 3, 'size_CL': 23, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 200.00 MiB (GPU 0; 23.65 GiB total capacity; 2.94 GiB already allocated; 15.94 MiB free; 3.31 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 94, in _init_group
    state['exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
9a20df4c,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 8, 'num_CL': 3, 'size_CL': 30, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 440.00 MiB (GPU 0; 23.65 GiB total capacity; 3.40 GiB already allocated; 61.94 MiB free; 3.45 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
a5c8b989,"{'batch_size': 128, 'num_HL': 5, 'latent_dim': 16, 'num_CL': 4, 'size_CL': 32, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 228.00 MiB (GPU 0; 23.65 GiB total capacity; 4.98 GiB already allocated; 153.94 MiB free; 5.18 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 94, in _init_group
    state['exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
9e05dae3,"{'batch_size': 128, 'num_HL': 6, 'latent_dim': 17, 'num_CL': 3, 'size_CL': 29, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 220.00 MiB (GPU 0; 23.65 GiB total capacity; 4.96 GiB already allocated; 17.94 MiB free; 5.32 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 92, in _init_group
    state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
dcfd78f2,"{'batch_size': 128, 'num_HL': 8, 'latent_dim': 17, 'num_CL': 3, 'size_CL': 10, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 148.00 MiB (GPU 0; 23.65 GiB total capacity; 1.68 GiB already allocated; 93.94 MiB free; 1.90 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
335800d8,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 18, 'num_CL': 3, 'size_CL': 25, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 148.00 MiB (GPU 0; 23.65 GiB total capacity; 1.90 GiB already allocated; 63.94 MiB free; 1.93 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
d0ede739,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 16, 'num_CL': 3, 'size_CL': 19, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 86.00 MiB (GPU 0; 23.65 GiB total capacity; 1.10 GiB already allocated; 65.94 MiB free; 1.93 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
fec00354,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 18, 'num_CL': 3, 'size_CL': 23, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 126.00 MiB (GPU 0; 23.65 GiB total capacity; 1.14 GiB already allocated; 65.94 MiB free; 1.93 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
b4cea864,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 17, 'num_CL': 3, 'size_CL': 18, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 78.00 MiB (GPU 0; 23.65 GiB total capacity; 1.09 GiB already allocated; 65.94 MiB free; 1.93 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
75636616,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 16, 'num_CL': 3, 'size_CL': 28, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 186.00 MiB (GPU 0; 23.65 GiB total capacity; 1.20 GiB already allocated; 171.94 MiB free; 1.96 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
d54d3661,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 15, 'num_CL': 3, 'size_CL': 17, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 70.00 MiB (GPU 0; 23.65 GiB total capacity; 1.30 GiB already allocated; 31.94 MiB free; 2.10 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
a235e52f,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 18, 'num_CL': 3, 'size_CL': 19, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 86.00 MiB (GPU 0; 23.65 GiB total capacity; 1.29 GiB already allocated; 85.94 MiB free; 2.05 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
47f079f4,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 17, 'num_CL': 3, 'size_CL': 15, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 224.00 MiB (GPU 0; 23.65 GiB total capacity; 1.77 GiB already allocated; 131.94 MiB free; 2.00 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
2c937254,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 18, 'num_CL': 3, 'size_CL': 16, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 78.00 MiB (GPU 0; 23.65 GiB total capacity; 1.84 GiB already allocated; 51.94 MiB free; 2.08 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
0af8acc3,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 17, 'num_CL': 3, 'size_CL': 25, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 148.00 MiB (GPU 0; 23.65 GiB total capacity; 1.16 GiB already allocated; 127.94 MiB free; 2.00 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
b53da500,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 18, 'num_CL': 3, 'size_CL': 18, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 78.00 MiB (GPU 0; 23.65 GiB total capacity; 1.27 GiB already allocated; 49.94 MiB free; 2.08 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
f1c74ca9,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 17, 'num_CL': 3, 'size_CL': 21, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 104.00 MiB (GPU 0; 23.65 GiB total capacity; 1.35 GiB already allocated; 23.94 MiB free; 2.10 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
0d605408,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 16, 'num_CL': 3, 'size_CL': 16, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 82.00 MiB (GPU 0; 23.65 GiB total capacity; 1.38 GiB already allocated; 21.94 MiB free; 2.10 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
80189f54,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 15, 'num_CL': 3, 'size_CL': 24, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 354.00 MiB (GPU 0; 23.65 GiB total capacity; 2.05 GiB already allocated; 263.94 MiB free; 3.24 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
fb807be4,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 18, 'num_CL': 3, 'size_CL': 17, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 70.00 MiB (GPU 0; 23.65 GiB total capacity; 1.48 GiB already allocated; 55.94 MiB free; 2.31 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 94, in _init_group
    state['exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
0eea4c89,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 15, 'num_CL': 3, 'size_CL': 30, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 212.00 MiB (GPU 0; 23.65 GiB total capacity; 1.48 GiB already allocated; 149.94 MiB free; 2.21 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
6e68e03e,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 16, 'num_CL': 3, 'size_CL': 27, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 230.00 MiB (GPU 0; 23.65 GiB total capacity; 2.18 GiB already allocated; 127.94 MiB free; 2.22 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 94, in _init_group
    state['exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
57013cc8,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 15, 'num_CL': 3, 'size_CL': 22, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 326.00 MiB (GPU 0; 23.65 GiB total capacity; 2.65 GiB already allocated; 123.94 MiB free; 3.26 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
376af4be,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 17, 'num_CL': 3, 'size_CL': 30, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 212.00 MiB (GPU 0; 23.65 GiB total capacity; 2.71 GiB already allocated; 143.94 MiB free; 2.88 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
34ba47ea,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 18, 'num_CL': 3, 'size_CL': 31, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 302.00 MiB (GPU 0; 23.65 GiB total capacity; 2.57 GiB already allocated; 289.94 MiB free; 2.74 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 92, in _init_group
    state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
715ec86c,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 17, 'num_CL': 3, 'size_CL': 32, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 242.00 MiB (GPU 0; 23.65 GiB total capacity; 2.14 GiB already allocated; 79.94 MiB free; 2.95 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
937401ca,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 17, 'num_CL': 3, 'size_CL': 27, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 172.00 MiB (GPU 0; 23.65 GiB total capacity; 1.87 GiB already allocated; 19.94 MiB free; 2.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
50d78dff,"{'batch_size': 128, 'num_HL': 4, 'latent_dim': 14, 'num_CL': 4, 'size_CL': 14, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 154.00 MiB (GPU 0; 23.65 GiB total capacity; 2.09 GiB already allocated; 125.94 MiB free; 2.59 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
