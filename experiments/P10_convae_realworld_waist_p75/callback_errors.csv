trial_id,config,error_type,error_message,error_traceback
f0d9294d,"{'batch_size': 64, 'num_CL': 2, 'size_CL': 30, 'kernel': 2, 'num_HL': 4, 'latent_dim': 110, 'opt_lr': 2.9052312681388772e-05, 'opt_wd': 1.4170897520374827e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 332.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 258.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 1146937 has 3.05 GiB memory in use. Process 1148589 has 6.55 GiB memory in use. Of the allocated memory 6.25 GiB is allocated by PyTorch, and 27.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 132, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 506, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
c798de2a,"{'batch_size': 128, 'num_CL': 4, 'size_CL': 17, 'kernel': 3, 'num_HL': 4, 'latent_dim': 22, 'opt_lr': 1.4874198054005052e-05, 'opt_wd': 8.479576442579225e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 178.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 96.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 1146937 has 3.19 GiB memory in use. Process 1148589 has 6.57 GiB memory in use. Of the allocated memory 2.82 GiB is allocated by PyTorch, and 101.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 132, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 302, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 1475, in relu
    result = torch.relu(input)
"
31c30616,"{'batch_size': 64, 'num_CL': 3, 'size_CL': 24, 'kernel': 3, 'num_HL': 4, 'latent_dim': 72, 'opt_lr': 7.448450124423575e-05, 'opt_wd': 8.215188665059505e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 208.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 22.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 1146937 has 3.26 GiB memory in use. Process 1148589 has 6.57 GiB memory in use. Of the allocated memory 2.74 GiB is allocated by PyTorch, and 256.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 132, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 444, in _multi_tensor_adam
    device_grads = torch._foreach_add(device_grads, device_params, alpha=weight_decay)
"
48160386,"{'batch_size': 128, 'num_CL': 2, 'size_CL': 24, 'kernel': 3, 'num_HL': 3, 'latent_dim': 222, 'opt_lr': 0.0003726512163031529, 'opt_wd': 1.7928463293100317e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 66.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 48.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 1146937 has 3.47 GiB memory in use. Process 1148589 has 6.34 GiB memory in use. Of the allocated memory 2.71 GiB is allocated by PyTorch, and 502.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 132, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 506, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
03afea8a,"{'batch_size': 64, 'num_CL': 4, 'size_CL': 27, 'kernel': 3, 'num_HL': 4, 'latent_dim': 10, 'opt_lr': 0.0003905717030613402, 'opt_wd': 9.82296121844123e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 260.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 168.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 1146937 has 3.49 GiB memory in use. Process 1148589 has 6.20 GiB memory in use. Of the allocated memory 4.82 GiB is allocated by PyTorch, and 1.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 132, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 506, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
b01b0695,"{'batch_size': 128, 'num_CL': 3, 'size_CL': 32, 'kernel': 3, 'num_HL': 2, 'latent_dim': 121, 'opt_lr': 0.000519468849088436, 'opt_wd': 1.2955892586817638e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 248.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 140.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 1146937 has 3.49 GiB memory in use. Process 1148589 has 6.23 GiB memory in use. Of the allocated memory 3.20 GiB is allocated by PyTorch, and 10.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 132, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
d85cbafb,"{'batch_size': 128, 'num_CL': 4, 'size_CL': 29, 'kernel': 2, 'num_HL': 2, 'latent_dim': 154, 'opt_lr': 0.00025901911435854237, 'opt_wd': 5.202809178809927e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 208.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 140.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 1146937 has 3.49 GiB memory in use. Process 1148589 has 6.23 GiB memory in use. Of the allocated memory 2.68 GiB is allocated by PyTorch, and 546.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 132, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
321e4738,"{'batch_size': 128, 'num_CL': 4, 'size_CL': 20, 'kernel': 4, 'num_HL': 4, 'latent_dim': 132, 'opt_lr': 1.0731702874525138e-05, 'opt_wd': 3.5324355754789737e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 140.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 106.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 1146937 has 3.52 GiB memory in use. Process 1148589 has 6.23 GiB memory in use. Of the allocated memory 3.12 GiB is allocated by PyTorch, and 130.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 132, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
b557cfe4,"{'batch_size': 128, 'num_CL': 4, 'size_CL': 26, 'kernel': 2, 'num_HL': 4, 'latent_dim': 103, 'opt_lr': 4.233400855505366e-05, 'opt_wd': 6.852121190214603e-07}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 248.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 190.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 1146937 has 3.44 GiB memory in use. Process 1148589 has 6.23 GiB memory in use. Of the allocated memory 2.77 GiB is allocated by PyTorch, and 401.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 132, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 134, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 94, in _init_group
    state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
14a96bac,"{'batch_size': 128, 'num_CL': 4, 'size_CL': 32, 'kernel': 4, 'num_HL': 4, 'latent_dim': 20, 'opt_lr': 7.164399781029022e-05, 'opt_wd': 1.188040065058879e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 178.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 116.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 1146937 has 3.51 GiB memory in use. Process 1148589 has 6.23 GiB memory in use. Of the allocated memory 3.21 GiB is allocated by PyTorch, and 29.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 132, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 134, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 96, in _init_group
    state['exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
acc953d1,"{'batch_size': 128, 'num_CL': 3, 'size_CL': 30, 'kernel': 2, 'num_HL': 3, 'latent_dim': 206, 'opt_lr': 5.361215751548314e-05, 'opt_wd': 3.380738409122893e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 24.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 1146937 has 3.53 GiB memory in use. Process 1148589 has 6.30 GiB memory in use. Of the allocated memory 5.19 GiB is allocated by PyTorch, and 852.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 132, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
4560da6f,"{'batch_size': 64, 'num_CL': 3, 'size_CL': 28, 'kernel': 2, 'num_HL': 4, 'latent_dim': 93, 'opt_lr': 2.2782396691372808e-05, 'opt_wd': 2.159481429462802e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 216.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 1146937 has 7.28 GiB memory in use. Process 1148589 has 2.37 GiB memory in use. Of the allocated memory 6.61 GiB is allocated by PyTorch, and 405.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 132, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
f8e78c2e,"{'batch_size': 64, 'num_CL': 3, 'size_CL': 25, 'kernel': 2, 'num_HL': 2, 'latent_dim': 234, 'opt_lr': 0.0004809975272243931, 'opt_wd': 3.3225911213688723e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 156.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 2.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 1146937 has 7.31 GiB memory in use. Process 1148589 has 2.55 GiB memory in use. Of the allocated memory 2.21 GiB is allocated by PyTorch, and 67.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 132, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
1f5713cc,"{'batch_size': 64, 'num_CL': 3, 'size_CL': 31, 'kernel': 4, 'num_HL': 2, 'latent_dim': 23, 'opt_lr': 6.67936571815021e-05, 'opt_wd': 5.675662675483781e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 228.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 204.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 1146937 has 7.31 GiB memory in use. Process 1148589 has 2.35 GiB memory in use. Of the allocated memory 2.01 GiB is allocated by PyTorch, and 65.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 132, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 444, in _multi_tensor_adam
    device_grads = torch._foreach_add(device_grads, device_params, alpha=weight_decay)
"
0d38d265,"{'batch_size': 128, 'num_CL': 3, 'size_CL': 18, 'kernel': 3, 'num_HL': 3, 'latent_dim': 139, 'opt_lr': 5.541920661119026e-05, 'opt_wd': 9.989087518094475e-07}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 100.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 1146937 has 7.31 GiB memory in use. Process 1148589 has 2.45 GiB memory in use. Of the allocated memory 1.96 GiB is allocated by PyTorch, and 222.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 132, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
ebd146c5,"{'batch_size': 64, 'num_CL': 4, 'size_CL': 16, 'kernel': 3, 'num_HL': 3, 'latent_dim': 189, 'opt_lr': 0.00025158673409769153, 'opt_wd': 4.209065071959742e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 224.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 100.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 1146937 has 7.31 GiB memory in use. Process 1148589 has 2.45 GiB memory in use. Of the allocated memory 1.79 GiB is allocated by PyTorch, and 396.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 132, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 302, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 1475, in relu
    result = torch.relu(input)
"
bebfe12d,"{'batch_size': 128, 'num_CL': 3, 'size_CL': 19, 'kernel': 2, 'num_HL': 3, 'latent_dim': 270, 'opt_lr': 0.00011636966768649081, 'opt_wd': 3.471864152323129e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 120.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 102.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 1146937 has 7.31 GiB memory in use. Process 1148589 has 2.45 GiB memory in use. Of the allocated memory 1.63 GiB is allocated by PyTorch, and 560.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 132, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 506, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
fb65d9c5,"{'batch_size': 64, 'num_CL': 4, 'size_CL': 30, 'kernel': 3, 'num_HL': 2, 'latent_dim': 252, 'opt_lr': 8.872801804917833e-05, 'opt_wd': 6.5254106802569415e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 214.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 162.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 1146937 has 5.17 GiB memory in use. Process 1148589 has 4.53 GiB memory in use. Of the allocated memory 4.06 GiB is allocated by PyTorch, and 859.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 132, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 302, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 1475, in relu
    result = torch.relu(input)
"
37721f3a,"{'batch_size': 64, 'num_CL': 4, 'size_CL': 27, 'kernel': 3, 'num_HL': 2, 'latent_dim': 203, 'opt_lr': 5.333608693829357e-05, 'opt_wd': 4.91298521740556e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 376.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 340.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 1146937 has 5.18 GiB memory in use. Process 1148589 has 4.34 GiB memory in use. Of the allocated memory 3.26 GiB is allocated by PyTorch, and 821.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 132, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 302, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 1475, in relu
    result = torch.relu(input)
"
95002f17,"{'batch_size': 128, 'num_CL': 4, 'size_CL': 29, 'kernel': 2, 'num_HL': 2, 'latent_dim': 227, 'opt_lr': 9.922663521342669e-05, 'opt_wd': 2.3770304853435542e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 208.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 104.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 1146937 has 5.19 GiB memory in use. Process 1148589 has 4.57 GiB memory in use. Of the allocated memory 2.92 GiB is allocated by PyTorch, and 1.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 132, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
2fb1319c,"{'batch_size': 128, 'num_CL': 3, 'size_CL': 28, 'kernel': 3, 'num_HL': 2, 'latent_dim': 147, 'opt_lr': 0.0003470669016260597, 'opt_wd': 2.9106172303051324e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 386.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 1146937 has 5.21 GiB memory in use. Process 1148589 has 4.27 GiB memory in use. Of the allocated memory 3.07 GiB is allocated by PyTorch, and 944.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 132, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 302, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 1475, in relu
    result = torch.relu(input)
"
533760fc,"{'batch_size': 128, 'num_CL': 3, 'size_CL': 31, 'kernel': 3, 'num_HL': 2, 'latent_dim': 37, 'opt_lr': 0.00010552245433716506, 'opt_wd': 7.138901990759436e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 232.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 84.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 1146937 has 5.21 GiB memory in use. Process 1148589 has 4.56 GiB memory in use. Of the allocated memory 3.18 GiB is allocated by PyTorch, and 1.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 132, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
09e3346c,"{'batch_size': 128, 'num_CL': 4, 'size_CL': 31, 'kernel': 3, 'num_HL': 2, 'latent_dim': 174, 'opt_lr': 0.0002740202751903498, 'opt_wd': 1.6179793057460372e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 232.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 64.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 1146937 has 5.02 GiB memory in use. Process 1148589 has 4.77 GiB memory in use. Of the allocated memory 3.22 GiB is allocated by PyTorch, and 1.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 132, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
035c8064,"{'batch_size': 128, 'num_CL': 3, 'size_CL': 30, 'kernel': 3, 'num_HL': 3, 'latent_dim': 262, 'opt_lr': 7.03304966233332e-05, 'opt_wd': 4.563419363292733e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 102.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 24.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 1146937 has 5.07 GiB memory in use. Process 1148589 has 4.76 GiB memory in use. Of the allocated memory 4.27 GiB is allocated by PyTorch, and 214.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 132, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 165, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 77, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/optim/adam.py"", line 506, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
76bd107d,"{'batch_size': 128, 'num_CL': 4, 'size_CL': 24, 'kernel': 4, 'num_HL': 3, 'latent_dim': 221, 'opt_lr': 0.0004107080806280495, 'opt_wd': 4.30150729066623e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 330.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 328.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 1146937 has 4.34 GiB memory in use. Process 1148589 has 5.20 GiB memory in use. Of the allocated memory 3.73 GiB is allocated by PyTorch, and 335.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 132, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 302, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 1475, in relu
    result = torch.relu(input)
"
a9e9be6f,"{'batch_size': 64, 'num_CL': 3, 'size_CL': 23, 'kernel': 3, 'num_HL': 3, 'latent_dim': 236, 'opt_lr': 0.00022230562147536768, 'opt_wd': 3.8195304830118646e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 322.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 156.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 1146937 has 4.50 GiB memory in use. Process 1148589 has 5.20 GiB memory in use. Of the allocated memory 3.26 GiB is allocated by PyTorch, and 988.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 132, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 302, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 1475, in relu
    result = torch.relu(input)
"
54cbd0b1,"{'batch_size': 128, 'num_CL': 4, 'size_CL': 20, 'kernel': 4, 'num_HL': 4, 'latent_dim': 241, 'opt_lr': 0.00014001458805390547, 'opt_wd': 3.610711022461527e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 150.12 MiB is free. Process 448990 has 13.82 GiB memory in use. Process 1146937 has 4.51 GiB memory in use. Process 1148589 has 5.20 GiB memory in use. Of the allocated memory 3.67 GiB is allocated by PyTorch, and 1.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 132, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/transforms/topo_ae.py"", line 302, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1502, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/module.py"", line 1511, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.8/site-packages/torch/nn/functional.py"", line 1475, in relu
    result = torch.relu(input)
"
