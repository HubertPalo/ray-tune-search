trial_id,config,error_type,error_message,error_traceback
4a7c1ec9,"{'batch_size': 64, 'num_HL': 7, 'latent_dim': 19, 'num_CL': 3, 'size_CL': 20, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'IndexError'>,"too many indices for array: array is 1-dimensional, but 2 were indexed","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 187, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(val_data_loader, train_mode=False)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 88, in __one_epoch
    loss, loss_components = self.model(inputs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 61, in forward
    topo_error, topo_error_components = self.topo_sig(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 102, in forward
    sig1 = self._select_distances_from_pairs(distances1, pairs1)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 48, in _select_distances_from_pairs
    selected_distances = distance_matrix[(pairs_0[:, 0], pairs_0[:, 1])]
"
c1cd1fc0,"{'batch_size': 128, 'num_HL': 4, 'latent_dim': 25, 'num_CL': 3, 'size_CL': 31, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 174.00 MiB (GPU 0; 23.65 GiB total capacity; 5.98 GiB already allocated; 143.94 MiB free; 6.07 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
6eab277d,"{'batch_size': 64, 'num_HL': 4, 'latent_dim': 5, 'num_CL': 3, 'size_CL': 16, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 238.00 MiB (GPU 0; 23.65 GiB total capacity; 2.26 GiB already allocated; 3.94 MiB free; 2.30 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
ebfda8f4,"{'batch_size': 128, 'num_HL': 7, 'latent_dim': 10, 'num_CL': 3, 'size_CL': 19, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 22.00 MiB (GPU 0; 23.65 GiB total capacity; 2.34 GiB already allocated; 5.94 MiB free; 2.41 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 94, in _init_group
    state['exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
a1840818,"{'batch_size': 128, 'num_HL': 6, 'latent_dim': 28, 'num_CL': 3, 'size_CL': 13, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 28.00 MiB (GPU 0; 23.65 GiB total capacity; 2.06 GiB already allocated; 7.94 MiB free; 2.10 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
5e0befdb,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 8, 'num_CL': 2, 'size_CL': 26, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 164.00 MiB (GPU 0; 23.65 GiB total capacity; 1.78 GiB already allocated; 95.94 MiB free; 2.02 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
74c93864,"{'batch_size': 64, 'num_HL': 7, 'latent_dim': 18, 'num_CL': 3, 'size_CL': 15, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 94.00 MiB (GPU 0; 23.65 GiB total capacity; 1.95 GiB already allocated; 1.94 MiB free; 2.11 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
84b35a84,"{'batch_size': 64, 'num_HL': 8, 'latent_dim': 12, 'num_CL': 2, 'size_CL': 27, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 312.00 MiB (GPU 0; 23.65 GiB total capacity; 8.88 GiB already allocated; 299.94 MiB free; 9.10 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
e6fa3588,"{'batch_size': 64, 'num_HL': 5, 'latent_dim': 14, 'num_CL': 3, 'size_CL': 12, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 144.00 MiB (GPU 0; 23.65 GiB total capacity; 1.80 GiB already allocated; 45.94 MiB free; 1.91 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
ce4b980b,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 22, 'num_CL': 3, 'size_CL': 21, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 142.00 MiB (GPU 0; 23.65 GiB total capacity; 1.72 GiB already allocated; 21.94 MiB free; 1.93 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
a5b926be,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 7, 'num_CL': 2, 'size_CL': 31, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 460.00 MiB (GPU 0; 23.65 GiB total capacity; 3.20 GiB already allocated; 239.94 MiB free; 3.53 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
fb399f83,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 26, 'num_CL': 4, 'size_CL': 27, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 170.00 MiB (GPU 0; 23.65 GiB total capacity; 1.51 GiB already allocated; 9.94 MiB free; 1.52 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
ab060a48,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 32, 'num_CL': 4, 'size_CL': 22, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 158.00 MiB (GPU 0; 23.65 GiB total capacity; 1.35 GiB already allocated; 11.94 MiB free; 1.52 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 92, in _init_group
    state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
9514339a,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 36, 'num_CL': 4, 'size_CL': 16, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 238.00 MiB (GPU 0; 23.65 GiB total capacity; 1.81 GiB already allocated; 129.94 MiB free; 1.95 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
d8f89561,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 18, 'num_CL': 4, 'size_CL': 25, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 146.00 MiB (GPU 0; 23.65 GiB total capacity; 1.72 GiB already allocated; 41.94 MiB free; 2.03 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
b104b192,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 24, 'num_CL': 4, 'size_CL': 10, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 23.65 GiB total capacity; 355.02 MiB already allocated; 9.94 MiB free; 394.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
418bfb25,"{'batch_size': 64, 'num_HL': 8, 'latent_dim': 26, 'num_CL': 4, 'size_CL': 29, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 23.65 GiB total capacity; 6.67 GiB already allocated; 119.94 MiB free; 6.92 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 94, in _init_group
    state['exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
cc75c539,"{'batch_size': 64, 'num_HL': 5, 'latent_dim': 15, 'num_CL': 3, 'size_CL': 32, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 400.00 MiB (GPU 0; 23.65 GiB total capacity; 5.47 GiB already allocated; 351.94 MiB free; 6.69 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 92, in _init_group
    state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
dc29c8aa,"{'batch_size': 64, 'num_HL': 4, 'latent_dim': 24, 'num_CL': 3, 'size_CL': 29, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 52.00 MiB (GPU 0; 23.65 GiB total capacity; 2.08 GiB already allocated; 39.94 MiB free; 2.15 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
826240d2,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 19, 'num_CL': 3, 'size_CL': 2, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'IndexError'>,"too many indices for array: array is 1-dimensional, but 2 were indexed","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 187, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(val_data_loader, train_mode=False)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 88, in __one_epoch
    loss, loss_components = self.model(inputs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 61, in forward
    topo_error, topo_error_components = self.topo_sig(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 102, in forward
    sig1 = self._select_distances_from_pairs(distances1, pairs1)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 48, in _select_distances_from_pairs
    selected_distances = distance_matrix[(pairs_0[:, 0], pairs_0[:, 1])]
"
ff93c165,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 20, 'num_CL': 4, 'size_CL': 31, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'IndexError'>,"too many indices for array: array is 1-dimensional, but 2 were indexed","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 187, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(val_data_loader, train_mode=False)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 88, in __one_epoch
    loss, loss_components = self.model(inputs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 61, in forward
    topo_error, topo_error_components = self.topo_sig(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 102, in forward
    sig1 = self._select_distances_from_pairs(distances1, pairs1)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 48, in _select_distances_from_pairs
    selected_distances = distance_matrix[(pairs_0[:, 0], pairs_0[:, 1])]
"
d7a16b32,"{'batch_size': 64, 'num_HL': 6, 'latent_dim': 30, 'num_CL': 3, 'size_CL': 23, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 216.00 MiB (GPU 0; 23.65 GiB total capacity; 5.90 GiB already allocated; 139.94 MiB free; 6.37 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
e2ae0cfc,"{'batch_size': 128, 'num_HL': 4, 'latent_dim': 22, 'num_CL': 4, 'size_CL': 14, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 208.00 MiB (GPU 0; 23.65 GiB total capacity; 1.58 GiB already allocated; 3.94 MiB free; 1.83 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
79142a96,"{'batch_size': 64, 'num_HL': 8, 'latent_dim': 31, 'num_CL': 4, 'size_CL': 27, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 296.00 MiB (GPU 0; 23.65 GiB total capacity; 6.95 GiB already allocated; 261.94 MiB free; 7.54 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
ba7f90bf,"{'batch_size': 64, 'num_HL': 5, 'latent_dim': 14, 'num_CL': 2, 'size_CL': 26, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 156.00 MiB (GPU 0; 23.65 GiB total capacity; 2.70 GiB already allocated; 123.94 MiB free; 3.26 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 94, in _init_group
    state['exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
aba00ed2,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 2, 'num_CL': 3, 'size_CL': 11, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 166.00 MiB (GPU 0; 23.65 GiB total capacity; 485.01 MiB already allocated; 13.94 MiB free; 614.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
4f489286,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 23, 'num_CL': 4, 'size_CL': 30, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 210.00 MiB (GPU 0; 23.65 GiB total capacity; 485.06 MiB already allocated; 13.94 MiB free; 614.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
eb4e8d95,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 21, 'num_CL': 3, 'size_CL': 21, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 144.00 MiB (GPU 0; 23.65 GiB total capacity; 2.70 GiB already allocated; 13.94 MiB free; 3.26 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
acb05e06,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 6, 'num_CL': 4, 'size_CL': 17, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 92.00 MiB (GPU 0; 23.65 GiB total capacity; 485.03 MiB already allocated; 13.94 MiB free; 614.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
2dbf3e0b,"{'batch_size': 64, 'num_HL': 4, 'latent_dim': 36, 'num_CL': 2, 'size_CL': 19, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 134.00 MiB (GPU 0; 23.65 GiB total capacity; 485.02 MiB already allocated; 11.94 MiB free; 614.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
81ed17e5,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 18, 'num_CL': 4, 'size_CL': 7, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 2.82 GiB already allocated; 1.94 MiB free; 3.27 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 187, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(val_data_loader, train_mode=False)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 88, in __one_epoch
    loss, loss_components = self.model(inputs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 60, in forward
    ae_loss, ae_loss_comp = self.autoencoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 461, in forward
    x_reconst = self.decode(latent)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 451, in decode
    return self.decoder(z)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
4821f9df,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 34, 'num_CL': 4, 'size_CL': 23, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 126.00 MiB (GPU 0; 23.65 GiB total capacity; 485.04 MiB already allocated; 1.94 MiB free; 614.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
724c2b09,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 33, 'num_CL': 4, 'size_CL': 25, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 150.00 MiB (GPU 0; 23.65 GiB total capacity; 2.70 GiB already allocated; 13.94 MiB free; 3.26 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
4704469f,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 29, 'num_CL': 4, 'size_CL': 20, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 130.00 MiB (GPU 0; 23.65 GiB total capacity; 485.03 MiB already allocated; 13.94 MiB free; 614.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
0eb8bd2d,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 31, 'num_CL': 4, 'size_CL': 28, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 182.00 MiB (GPU 0; 23.65 GiB total capacity; 2.70 GiB already allocated; 13.94 MiB free; 3.26 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
da88b584,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 32, 'num_CL': 4, 'size_CL': 14, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 62.00 MiB (GPU 0; 23.65 GiB total capacity; 485.02 MiB already allocated; 13.94 MiB free; 614.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
0da8f849,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 25, 'num_CL': 4, 'size_CL': 16, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 60.00 MiB (GPU 0; 23.65 GiB total capacity; 2.94 GiB already allocated; 13.94 MiB free; 3.26 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
a26dd635,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 30, 'num_CL': 4, 'size_CL': 22, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 154.00 MiB (GPU 0; 23.65 GiB total capacity; 485.03 MiB already allocated; 13.94 MiB free; 614.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
3cb8374d,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 27, 'num_CL': 4, 'size_CL': 12, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 36.00 MiB (GPU 0; 23.65 GiB total capacity; 3.04 GiB already allocated; 13.94 MiB free; 3.26 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
3cdeb59b,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 34, 'num_CL': 4, 'size_CL': 32, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 316.00 MiB (GPU 0; 23.65 GiB total capacity; 485.06 MiB already allocated; 13.94 MiB free; 614.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
dfa0bcbd,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 28, 'num_CL': 4, 'size_CL': 24, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 138.00 MiB (GPU 0; 23.65 GiB total capacity; 2.70 GiB already allocated; 13.94 MiB free; 3.26 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
4070591b,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 25, 'num_CL': 4, 'size_CL': 10, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 26.00 MiB (GPU 0; 23.65 GiB total capacity; 544.28 MiB already allocated; 7.94 MiB free; 620.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
ecb2cf4c,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 23, 'num_CL': 4, 'size_CL': 26, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 214.00 MiB (GPU 0; 23.65 GiB total capacity; 2.70 GiB already allocated; 7.94 MiB free; 3.26 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
06d40901,"{'batch_size': 64, 'num_HL': 4, 'latent_dim': 33, 'num_CL': 3, 'size_CL': 18, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 120.00 MiB (GPU 0; 23.65 GiB total capacity; 485.02 MiB already allocated; 13.94 MiB free; 614.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
24c18c3a,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 29, 'num_CL': 4, 'size_CL': 22, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 114.00 MiB (GPU 0; 23.65 GiB total capacity; 485.04 MiB already allocated; 13.94 MiB free; 614.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
5099e888,"{'batch_size': 64, 'num_HL': 6, 'latent_dim': 21, 'num_CL': 4, 'size_CL': 30, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 364.00 MiB (GPU 0; 23.65 GiB total capacity; 2.70 GiB already allocated; 13.94 MiB free; 3.26 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
22f83e0c,"{'batch_size': 64, 'num_HL': 8, 'latent_dim': 26, 'num_CL': 3, 'size_CL': 9, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.65 GiB total capacity; 544.47 MiB already allocated; 13.94 MiB free; 614.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
39246e98,"{'batch_size': 64, 'num_HL': 5, 'latent_dim': 20, 'num_CL': 4, 'size_CL': 15, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 88.00 MiB (GPU 0; 23.65 GiB total capacity; 2.70 GiB already allocated; 13.94 MiB free; 3.26 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
14db7c94,"{'batch_size': 128, 'num_HL': 6, 'latent_dim': 28, 'num_CL': 4, 'size_CL': 15, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 220.00 MiB (GPU 0; 23.65 GiB total capacity; 2.93 GiB already allocated; 47.94 MiB free; 3.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
bd935a26,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 16, 'num_CL': 4, 'size_CL': 17, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 92.00 MiB (GPU 0; 23.65 GiB total capacity; 485.03 MiB already allocated; 37.94 MiB free; 614.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
f4925e61,"{'batch_size': 64, 'num_HL': 7, 'latent_dim': 32, 'num_CL': 4, 'size_CL': 12, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 42.00 MiB (GPU 0; 23.65 GiB total capacity; 3.07 GiB already allocated; 37.94 MiB free; 3.27 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
a3d987cd,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 31, 'num_CL': 4, 'size_CL': 25, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 146.00 MiB (GPU 0; 23.65 GiB total capacity; 2.70 GiB already allocated; 47.94 MiB free; 3.26 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
b2e19c52,"{'batch_size': 64, 'num_HL': 4, 'latent_dim': 22, 'num_CL': 3, 'size_CL': 19, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 23.65 GiB total capacity; 1.39 GiB already allocated; 21.94 MiB free; 1.47 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
649a23fa,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 35, 'num_CL': 4, 'size_CL': 28, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 23.65 GiB total capacity; 2.25 GiB already allocated; 135.94 MiB free; 2.70 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
b24c9313,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 11, 'num_CL': 3, 'size_CL': 21, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 142.00 MiB (GPU 0; 23.65 GiB total capacity; 2.08 GiB already allocated; 125.94 MiB free; 2.69 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
6468e3d7,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 27, 'num_CL': 4, 'size_CL': 13, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 196.00 MiB (GPU 0; 23.65 GiB total capacity; 1.08 GiB already allocated; 151.94 MiB free; 1.45 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
0e1bdbd4,"{'batch_size': 64, 'num_HL': 4, 'latent_dim': 19, 'num_CL': 4, 'size_CL': 18, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 114.00 MiB (GPU 0; 23.65 GiB total capacity; 1.26 GiB already allocated; 7.94 MiB free; 1.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 92, in _init_group
    state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
833975be,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 33, 'num_CL': 4, 'size_CL': 28, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 254.00 MiB (GPU 0; 23.65 GiB total capacity; 1.37 GiB already allocated; 203.94 MiB free; 1.39 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
983ccb52,"{'batch_size': 64, 'num_HL': 5, 'latent_dim': 26, 'num_CL': 4, 'size_CL': 15, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'IndexError'>,"too many indices for array: array is 1-dimensional, but 2 were indexed","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 187, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(val_data_loader, train_mode=False)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 88, in __one_epoch
    loss, loss_components = self.model(inputs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 61, in forward
    topo_error, topo_error_components = self.topo_sig(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 102, in forward
    sig1 = self._select_distances_from_pairs(distances1, pairs1)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 48, in _select_distances_from_pairs
    selected_distances = distance_matrix[(pairs_0[:, 0], pairs_0[:, 1])]
"
2f5e0553,"{'batch_size': 128, 'num_HL': 6, 'latent_dim': 29, 'num_CL': 2, 'size_CL': 24, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 156.00 MiB (GPU 0; 23.65 GiB total capacity; 7.07 GiB already allocated; 57.94 MiB free; 7.54 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
d6091f67,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 8, 'num_CL': 3, 'size_CL': 16, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 238.00 MiB (GPU 0; 23.65 GiB total capacity; 1.09 GiB already allocated; 119.94 MiB free; 1.39 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
66b3e1d5,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 13, 'num_CL': 3, 'size_CL': 23, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 166.00 MiB (GPU 0; 23.65 GiB total capacity; 1.05 GiB already allocated; 59.94 MiB free; 1.45 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
8ea936fd,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 21, 'num_CL': 4, 'size_CL': 32, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 248.00 MiB (GPU 0; 23.65 GiB total capacity; 1.24 GiB already allocated; 235.94 MiB free; 1.28 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
4671e8df,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 30, 'num_CL': 4, 'size_CL': 31, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 304.00 MiB (GPU 0; 23.65 GiB total capacity; 1.37 GiB already allocated; 135.94 MiB free; 1.38 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
a612ca50,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 31, 'num_CL': 4, 'size_CL': 25, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 370.00 MiB (GPU 0; 23.65 GiB total capacity; 2.17 GiB already allocated; 157.94 MiB free; 2.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
17add9a2,"{'batch_size': 64, 'num_HL': 4, 'latent_dim': 28, 'num_CL': 4, 'size_CL': 19, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 130.00 MiB (GPU 0; 23.65 GiB total capacity; 2.40 GiB already allocated; 33.94 MiB free; 2.70 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
79e38ba3,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 18, 'num_CL': 4, 'size_CL': 26, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 210.00 MiB (GPU 0; 23.65 GiB total capacity; 2.53 GiB already allocated; 23.94 MiB free; 2.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
89c354d9,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 25, 'num_CL': 4, 'size_CL': 30, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 436.00 MiB (GPU 0; 23.65 GiB total capacity; 3.79 GiB already allocated; 95.94 MiB free; 4.18 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
2fa677a2,"{'batch_size': 64, 'num_HL': 8, 'latent_dim': 15, 'num_CL': 3, 'size_CL': 10, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 150.00 MiB (GPU 0; 23.65 GiB total capacity; 1.73 GiB already allocated; 121.94 MiB free; 1.83 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
5fd13c69,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 17, 'num_CL': 4, 'size_CL': 31, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 224.00 MiB (GPU 0; 23.65 GiB total capacity; 1.13 GiB already allocated; 127.94 MiB free; 1.39 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
1283ad83,"{'batch_size': 64, 'num_HL': 4, 'latent_dim': 20, 'num_CL': 3, 'size_CL': 21, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 160.00 MiB (GPU 0; 23.65 GiB total capacity; 1.06 GiB already allocated; 65.94 MiB free; 1.45 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
29f2c88b,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 22, 'num_CL': 4, 'size_CL': 27, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 400.00 MiB (GPU 0; 23.65 GiB total capacity; 2.89 GiB already allocated; 285.94 MiB free; 3.95 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
23e31217,"{'batch_size': 64, 'num_HL': 5, 'latent_dim': 27, 'num_CL': 2, 'size_CL': 12, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'IndexError'>,"too many indices for array: array is 1-dimensional, but 2 were indexed","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 187, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(val_data_loader, train_mode=False)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 88, in __one_epoch
    loss, loss_components = self.model(inputs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 61, in forward
    topo_error, topo_error_components = self.topo_sig(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 102, in forward
    sig1 = self._select_distances_from_pairs(distances1, pairs1)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 48, in _select_distances_from_pairs
    selected_distances = distance_matrix[(pairs_0[:, 0], pairs_0[:, 1])]
"
87783d7e,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 26, 'num_CL': 4, 'size_CL': 24, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'IndexError'>,"too many indices for array: array is 1-dimensional, but 2 were indexed","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 187, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(val_data_loader, train_mode=False)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 88, in __one_epoch
    loss, loss_components = self.model(inputs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 61, in forward
    topo_error, topo_error_components = self.topo_sig(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 102, in forward
    sig1 = self._select_distances_from_pairs(distances1, pairs1)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 48, in _select_distances_from_pairs
    selected_distances = distance_matrix[(pairs_0[:, 0], pairs_0[:, 1])]
"
d6a96efa,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 21, 'num_CL': 4, 'size_CL': 18, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'IndexError'>,"too many indices for array: array is 1-dimensional, but 2 were indexed","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 187, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(val_data_loader, train_mode=False)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 88, in __one_epoch
    loss, loss_components = self.model(inputs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 61, in forward
    topo_error, topo_error_components = self.topo_sig(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 102, in forward
    sig1 = self._select_distances_from_pairs(distances1, pairs1)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 48, in _select_distances_from_pairs
    selected_distances = distance_matrix[(pairs_0[:, 0], pairs_0[:, 1])]
"
7f79098d,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 34, 'num_CL': 4, 'size_CL': 23, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'IndexError'>,"too many indices for array: array is 1-dimensional, but 2 were indexed","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 187, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(val_data_loader, train_mode=False)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 88, in __one_epoch
    loss, loss_components = self.model(inputs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 61, in forward
    topo_error, topo_error_components = self.topo_sig(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 102, in forward
    sig1 = self._select_distances_from_pairs(distances1, pairs1)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 48, in _select_distances_from_pairs
    selected_distances = distance_matrix[(pairs_0[:, 0], pairs_0[:, 1])]
"
914fb9a2,"{'batch_size': 64, 'num_HL': 4, 'latent_dim': 28, 'num_CL': 4, 'size_CL': 26, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 246.00 MiB (GPU 0; 23.65 GiB total capacity; 2.75 GiB already allocated; 47.94 MiB free; 2.92 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 92, in _init_group
    state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
a25466a3,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 33, 'num_CL': 3, 'size_CL': 19, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 284.00 MiB (GPU 0; 23.65 GiB total capacity; 1.82 GiB already allocated; 203.94 MiB free; 2.19 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
d4989241,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 35, 'num_CL': 4, 'size_CL': 17, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'IndexError'>,"too many indices for array: array is 1-dimensional, but 2 were indexed","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 187, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(val_data_loader, train_mode=False)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 88, in __one_epoch
    loss, loss_components = self.model(inputs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 61, in forward
    topo_error, topo_error_components = self.topo_sig(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 102, in forward
    sig1 = self._select_distances_from_pairs(distances1, pairs1)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 48, in _select_distances_from_pairs
    selected_distances = distance_matrix[(pairs_0[:, 0], pairs_0[:, 1])]
"
2aa19a73,"{'batch_size': 128, 'num_HL': 4, 'latent_dim': 22, 'num_CL': 4, 'size_CL': 16, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 236.00 MiB (GPU 0; 23.65 GiB total capacity; 2.44 GiB already allocated; 205.94 MiB free; 3.95 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
a80cdb6c,"{'batch_size': 64, 'num_HL': 5, 'latent_dim': 25, 'num_CL': 4, 'size_CL': 30, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 102.00 MiB (GPU 0; 23.65 GiB total capacity; 3.99 GiB already allocated; 51.94 MiB free; 4.10 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 92, in _init_group
    state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
82bb5598,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 32, 'num_CL': 3, 'size_CL': 29, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 426.00 MiB (GPU 0; 23.65 GiB total capacity; 3.23 GiB already allocated; 133.94 MiB free; 4.26 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
e78e5ab5,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 26, 'num_CL': 4, 'size_CL': 15, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'IndexError'>,"too many indices for array: array is 1-dimensional, but 2 were indexed","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 187, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(val_data_loader, train_mode=False)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 88, in __one_epoch
    loss, loss_components = self.model(inputs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 61, in forward
    topo_error, topo_error_components = self.topo_sig(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 102, in forward
    sig1 = self._select_distances_from_pairs(distances1, pairs1)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 48, in _select_distances_from_pairs
    selected_distances = distance_matrix[(pairs_0[:, 0], pairs_0[:, 1])]
"
2c0f01b3,"{'batch_size': 128, 'num_HL': 6, 'latent_dim': 31, 'num_CL': 4, 'size_CL': 11, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 164.00 MiB (GPU 0; 23.65 GiB total capacity; 1.63 GiB already allocated; 127.94 MiB free; 2.19 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
d6d5d15a,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 32, 'num_CL': 4, 'size_CL': 8, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'IndexError'>,"too many indices for array: array is 1-dimensional, but 2 were indexed","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 187, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(val_data_loader, train_mode=False)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 88, in __one_epoch
    loss, loss_components = self.model(inputs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 61, in forward
    topo_error, topo_error_components = self.topo_sig(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 102, in forward
    sig1 = self._select_distances_from_pairs(distances1, pairs1)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 48, in _select_distances_from_pairs
    selected_distances = distance_matrix[(pairs_0[:, 0], pairs_0[:, 1])]
"
e4070b11,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 23, 'num_CL': 4, 'size_CL': 28, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 82.00 MiB (GPU 0; 23.65 GiB total capacity; 1.83 GiB already allocated; 67.94 MiB free; 2.24 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 94, in _init_group
    state['exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
8a97f747,"{'batch_size': 64, 'num_HL': 8, 'latent_dim': 29, 'num_CL': 3, 'size_CL': 27, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 230.00 MiB (GPU 0; 23.65 GiB total capacity; 2.16 GiB already allocated; 149.94 MiB free; 2.16 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
76b83760,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 10, 'num_CL': 4, 'size_CL': 9, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'IndexError'>,"too many indices for array: array is 1-dimensional, but 2 were indexed","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 187, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(val_data_loader, train_mode=False)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 88, in __one_epoch
    loss, loss_components = self.model(inputs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 61, in forward
    topo_error, topo_error_components = self.topo_sig(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 102, in forward
    sig1 = self._select_distances_from_pairs(distances1, pairs1)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 48, in _select_distances_from_pairs
    selected_distances = distance_matrix[(pairs_0[:, 0], pairs_0[:, 1])]
"
cd3e841d,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 33, 'num_CL': 4, 'size_CL': 20, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 23.65 GiB total capacity; 1.81 GiB already allocated; 53.94 MiB free; 2.26 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
673557ce,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 15, 'num_CL': 4, 'size_CL': 25, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'IndexError'>,"too many indices for array: array is 1-dimensional, but 2 were indexed","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 187, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(val_data_loader, train_mode=False)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 88, in __one_epoch
    loss, loss_components = self.model(inputs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 61, in forward
    topo_error, topo_error_components = self.topo_sig(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 102, in forward
    sig1 = self._select_distances_from_pairs(distances1, pairs1)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 48, in _select_distances_from_pairs
    selected_distances = distance_matrix[(pairs_0[:, 0], pairs_0[:, 1])]
"
6a9e421d,"{'batch_size': 64, 'num_HL': 4, 'latent_dim': 3, 'num_CL': 2, 'size_CL': 23, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 194.00 MiB (GPU 0; 23.65 GiB total capacity; 2.17 GiB already allocated; 15.94 MiB free; 2.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 92, in _init_group
    state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
d472f345,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 22, 'num_CL': 4, 'size_CL': 18, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 262.00 MiB (GPU 0; 23.65 GiB total capacity; 2.37 GiB already allocated; 181.94 MiB free; 3.01 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
e435b827,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 25, 'num_CL': 2, 'size_CL': 24, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 354.00 MiB (GPU 0; 23.65 GiB total capacity; 3.13 GiB already allocated; 47.94 MiB free; 4.27 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
e2a00714,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 30, 'num_CL': 4, 'size_CL': 19, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'IndexError'>,"too many indices for array: array is 1-dimensional, but 2 were indexed","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 187, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(val_data_loader, train_mode=False)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 88, in __one_epoch
    loss, loss_components = self.model(inputs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 61, in forward
    topo_error, topo_error_components = self.topo_sig(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 102, in forward
    sig1 = self._select_distances_from_pairs(distances1, pairs1)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 48, in _select_distances_from_pairs
    selected_distances = distance_matrix[(pairs_0[:, 0], pairs_0[:, 1])]
"
82fefe69,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 29, 'num_CL': 4, 'size_CL': 9, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'IndexError'>,"too many indices for array: array is 1-dimensional, but 2 were indexed","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 187, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(val_data_loader, train_mode=False)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 88, in __one_epoch
    loss, loss_components = self.model(inputs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 61, in forward
    topo_error, topo_error_components = self.topo_sig(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 102, in forward
    sig1 = self._select_distances_from_pairs(distances1, pairs1)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 48, in _select_distances_from_pairs
    selected_distances = distance_matrix[(pairs_0[:, 0], pairs_0[:, 1])]
"
216bbbad,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 30, 'num_CL': 4, 'size_CL': 29, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'IndexError'>,"too many indices for array: array is 1-dimensional, but 2 were indexed","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 187, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(val_data_loader, train_mode=False)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 88, in __one_epoch
    loss, loss_components = self.model(inputs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 61, in forward
    topo_error, topo_error_components = self.topo_sig(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 102, in forward
    sig1 = self._select_distances_from_pairs(distances1, pairs1)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 48, in _select_distances_from_pairs
    selected_distances = distance_matrix[(pairs_0[:, 0], pairs_0[:, 1])]
"
8d19516e,"{'batch_size': 128, 'num_HL': 7, 'latent_dim': 33, 'num_CL': 4, 'size_CL': 21, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 176.00 MiB (GPU 0; 23.65 GiB total capacity; 6.25 GiB already allocated; 63.94 MiB free; 6.36 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
f5414d7d,"{'batch_size': 64, 'num_HL': 5, 'latent_dim': 28, 'num_CL': 3, 'size_CL': 21, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 170.00 MiB (GPU 0; 23.65 GiB total capacity; 2.50 GiB already allocated; 115.94 MiB free; 2.94 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 94, in _init_group
    state['exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
dbaf0497,"{'batch_size': 128, 'num_HL': 4, 'latent_dim': 35, 'num_CL': 4, 'size_CL': 32, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 356.00 MiB (GPU 0; 23.65 GiB total capacity; 2.71 GiB already allocated; 323.94 MiB free; 2.74 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
4cbe2721,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 21, 'num_CL': 4, 'size_CL': 10, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'IndexError'>,"too many indices for array: array is 1-dimensional, but 2 were indexed","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 187, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(val_data_loader, train_mode=False)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 88, in __one_epoch
    loss, loss_components = self.model(inputs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 61, in forward
    topo_error, topo_error_components = self.topo_sig(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 102, in forward
    sig1 = self._select_distances_from_pairs(distances1, pairs1)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 48, in _select_distances_from_pairs
    selected_distances = distance_matrix[(pairs_0[:, 0], pairs_0[:, 1])]
"
b367a32a,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 27, 'num_CL': 4, 'size_CL': 25, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'IndexError'>,"too many indices for array: array is 1-dimensional, but 2 were indexed","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 187, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(val_data_loader, train_mode=False)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 88, in __one_epoch
    loss, loss_components = self.model(inputs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 61, in forward
    topo_error, topo_error_components = self.topo_sig(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 102, in forward
    sig1 = self._select_distances_from_pairs(distances1, pairs1)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 48, in _select_distances_from_pairs
    selected_distances = distance_matrix[(pairs_0[:, 0], pairs_0[:, 1])]
"
e31c2611,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 23, 'num_CL': 4, 'size_CL': 16, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 234.00 MiB (GPU 0; 23.65 GiB total capacity; 1.75 GiB already allocated; 67.94 MiB free; 2.42 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
6bec64f0,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 14, 'num_CL': 3, 'size_CL': 15, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 148.00 MiB (GPU 0; 23.65 GiB total capacity; 1.74 GiB already allocated; 63.94 MiB free; 2.42 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
7fc1db30,"{'batch_size': 64, 'num_HL': 8, 'latent_dim': 32, 'num_CL': 4, 'size_CL': 19, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 54.00 MiB (GPU 0; 23.65 GiB total capacity; 5.66 GiB already allocated; 3.94 MiB free; 5.84 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
49e2ee28,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 21, 'num_CL': 4, 'size_CL': 5, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'IndexError'>,"too many indices for array: array is 1-dimensional, but 2 were indexed","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 187, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(val_data_loader, train_mode=False)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 88, in __one_epoch
    loss, loss_components = self.model(inputs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 61, in forward
    topo_error, topo_error_components = self.topo_sig(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 102, in forward
    sig1 = self._select_distances_from_pairs(distances1, pairs1)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 48, in _select_distances_from_pairs
    selected_distances = distance_matrix[(pairs_0[:, 0], pairs_0[:, 1])]
"
b8b2a4f8,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 33, 'num_CL': 4, 'size_CL': 15, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'IndexError'>,"too many indices for array: array is 1-dimensional, but 2 were indexed","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 187, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(val_data_loader, train_mode=False)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 88, in __one_epoch
    loss, loss_components = self.model(inputs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 61, in forward
    topo_error, topo_error_components = self.topo_sig(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 102, in forward
    sig1 = self._select_distances_from_pairs(distances1, pairs1)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 48, in _select_distances_from_pairs
    selected_distances = distance_matrix[(pairs_0[:, 0], pairs_0[:, 1])]
"
a71f4a46,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 24, 'num_CL': 4, 'size_CL': 7, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'IndexError'>,"too many indices for array: array is 1-dimensional, but 2 were indexed","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 187, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(val_data_loader, train_mode=False)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 88, in __one_epoch
    loss, loss_components = self.model(inputs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 61, in forward
    topo_error, topo_error_components = self.topo_sig(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 102, in forward
    sig1 = self._select_distances_from_pairs(distances1, pairs1)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 48, in _select_distances_from_pairs
    selected_distances = distance_matrix[(pairs_0[:, 0], pairs_0[:, 1])]
"
a451578f,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 34, 'num_CL': 4, 'size_CL': 9, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'IndexError'>,"too many indices for array: array is 1-dimensional, but 2 were indexed","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 187, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(val_data_loader, train_mode=False)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 88, in __one_epoch
    loss, loss_components = self.model(inputs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 61, in forward
    topo_error, topo_error_components = self.topo_sig(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 102, in forward
    sig1 = self._select_distances_from_pairs(distances1, pairs1)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 48, in _select_distances_from_pairs
    selected_distances = distance_matrix[(pairs_0[:, 0], pairs_0[:, 1])]
"
f43860fe,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 32, 'num_CL': 4, 'size_CL': 3, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'IndexError'>,"too many indices for array: array is 1-dimensional, but 2 were indexed","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 187, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(val_data_loader, train_mode=False)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 88, in __one_epoch
    loss, loss_components = self.model(inputs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 61, in forward
    topo_error, topo_error_components = self.topo_sig(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 102, in forward
    sig1 = self._select_distances_from_pairs(distances1, pairs1)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 48, in _select_distances_from_pairs
    selected_distances = distance_matrix[(pairs_0[:, 0], pairs_0[:, 1])]
"
b9168c4b,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 20, 'num_CL': 4, 'size_CL': 13, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 126.00 MiB (GPU 0; 23.65 GiB total capacity; 1.58 GiB already allocated; 95.94 MiB free; 2.10 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
f0744df4,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 29, 'num_CL': 4, 'size_CL': 8, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'IndexError'>,"too many indices for array: array is 1-dimensional, but 2 were indexed","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 187, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(val_data_loader, train_mode=False)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 88, in __one_epoch
    loss, loss_components = self.model(inputs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 61, in forward
    topo_error, topo_error_components = self.topo_sig(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 102, in forward
    sig1 = self._select_distances_from_pairs(distances1, pairs1)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_signature_distance.py"", line 48, in _select_distances_from_pairs
    selected_distances = distance_matrix[(pairs_0[:, 0], pairs_0[:, 1])]
"
d0059292,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 17, 'num_CL': 4, 'size_CL': 31, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 454.00 MiB (GPU 0; 23.65 GiB total capacity; 5.24 GiB already allocated; 339.94 MiB free; 5.90 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
e452a880,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 24, 'num_CL': 4, 'size_CL': 16, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 234.00 MiB (GPU 0; 23.65 GiB total capacity; 1.76 GiB already allocated; 153.94 MiB free; 2.27 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
92a7d6f2,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 33, 'num_CL': 4, 'size_CL': 28, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 242.00 MiB (GPU 0; 23.65 GiB total capacity; 2.31 GiB already allocated; 85.94 MiB free; 2.34 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 94, in _init_group
    state['exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
9e3efb19,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 33, 'num_CL': 4, 'size_CL': 24, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 178.00 MiB (GPU 0; 23.65 GiB total capacity; 2.17 GiB already allocated; 161.94 MiB free; 2.27 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
e30aec34,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 34, 'num_CL': 4, 'size_CL': 29, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 196.00 MiB (GPU 0; 23.65 GiB total capacity; 1.93 GiB already allocated; 151.94 MiB free; 2.28 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
ccac9dc1,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 34, 'num_CL': 4, 'size_CL': 26, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 210.00 MiB (GPU 0; 23.65 GiB total capacity; 2.54 GiB already allocated; 75.94 MiB free; 2.84 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
504a83cf,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 35, 'num_CL': 4, 'size_CL': 27, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 226.00 MiB (GPU 0; 23.65 GiB total capacity; 2.15 GiB already allocated; 75.94 MiB free; 2.84 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 94, in _init_group
    state['exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
4693592e,"{'batch_size': 128, 'num_HL': 7, 'latent_dim': 34, 'num_CL': 4, 'size_CL': 29, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 334.00 MiB (GPU 0; 23.65 GiB total capacity; 3.53 GiB already allocated; 299.94 MiB free; 4.78 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
ac803cf7,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 33, 'num_CL': 4, 'size_CL': 23, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 338.00 MiB (GPU 0; 23.65 GiB total capacity; 2.23 GiB already allocated; 35.94 MiB free; 2.96 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
87e08d46,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 32, 'num_CL': 3, 'size_CL': 31, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 228.00 MiB (GPU 0; 23.65 GiB total capacity; 2.68 GiB already allocated; 181.94 MiB free; 3.70 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
4ac53905,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 33, 'num_CL': 4, 'size_CL': 24, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 352.00 MiB (GPU 0; 23.65 GiB total capacity; 2.38 GiB already allocated; 37.94 MiB free; 3.10 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
2d676973,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 30, 'num_CL': 4, 'size_CL': 21, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 308.00 MiB (GPU 0; 23.65 GiB total capacity; 2.72 GiB already allocated; 35.94 MiB free; 3.70 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
547f4ea2,"{'batch_size': 128, 'num_HL': 6, 'latent_dim': 31, 'num_CL': 4, 'size_CL': 28, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 304.00 MiB (GPU 0; 23.65 GiB total capacity; 3.10 GiB already allocated; 31.94 MiB free; 3.70 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
51ca6742,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 30, 'num_CL': 4, 'size_CL': 26, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 386.00 MiB (GPU 0; 23.65 GiB total capacity; 2.36 GiB already allocated; 123.94 MiB free; 3.00 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
39ae21a8,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 32, 'num_CL': 4, 'size_CL': 32, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 112.00 MiB (GPU 0; 23.65 GiB total capacity; 2.61 GiB already allocated; 77.94 MiB free; 3.04 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 92, in _init_group
    state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
05365094,"{'batch_size': 64, 'num_HL': 7, 'latent_dim': 35, 'num_CL': 4, 'size_CL': 20, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 118.00 MiB (GPU 0; 23.65 GiB total capacity; 2.87 GiB already allocated; 73.94 MiB free; 3.05 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 92, in _init_group
    state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
25cad15f,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 31, 'num_CL': 4, 'size_CL': 30, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 448.00 MiB (GPU 0; 23.65 GiB total capacity; 3.48 GiB already allocated; 425.94 MiB free; 4.45 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
7323aed7,"{'batch_size': 64, 'num_HL': 8, 'latent_dim': 33, 'num_CL': 4, 'size_CL': 23, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 214.00 MiB (GPU 0; 23.65 GiB total capacity; 4.63 GiB already allocated; 105.94 MiB free; 4.76 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 92, in _init_group
    state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
f4760b88,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 29, 'num_CL': 4, 'size_CL': 28, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 248.00 MiB (GPU 0; 23.65 GiB total capacity; 3.00 GiB already allocated; 111.94 MiB free; 3.70 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
af0ed74c,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 36, 'num_CL': 4, 'size_CL': 32, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 238.00 MiB (GPU 0; 23.65 GiB total capacity; 2.81 GiB already allocated; 91.94 MiB free; 3.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
98ecfe31,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 28, 'num_CL': 4, 'size_CL': 22, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 322.00 MiB (GPU 0; 23.65 GiB total capacity; 2.08 GiB already allocated; 101.94 MiB free; 3.05 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
03178a62,"{'batch_size': 64, 'num_HL': 4, 'latent_dim': 7, 'num_CL': 3, 'size_CL': 27, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 258.00 MiB (GPU 0; 23.65 GiB total capacity; 4.79 GiB already allocated; 107.94 MiB free; 5.38 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
d592b649,"{'batch_size': 64, 'num_HL': 5, 'latent_dim': 31, 'num_CL': 4, 'size_CL': 30, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 334.00 MiB (GPU 0; 23.65 GiB total capacity; 4.58 GiB already allocated; 107.94 MiB free; 5.38 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 92, in _init_group
    state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
0ba87daa,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 30, 'num_CL': 4, 'size_CL': 25, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 374.00 MiB (GPU 0; 23.65 GiB total capacity; 2.25 GiB already allocated; 93.94 MiB free; 3.05 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
01bbc58c,"{'batch_size': 64, 'num_HL': 4, 'latent_dim': 32, 'num_CL': 3, 'size_CL': 20, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 142.00 MiB (GPU 0; 23.65 GiB total capacity; 2.79 GiB already allocated; 99.94 MiB free; 3.04 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
7235fcc6,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 35, 'num_CL': 4, 'size_CL': 16, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 84.00 MiB (GPU 0; 23.65 GiB total capacity; 3.02 GiB already allocated; 9.94 MiB free; 3.13 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
334b3470,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 30, 'num_CL': 4, 'size_CL': 17, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 68.00 MiB (GPU 0; 23.65 GiB total capacity; 3.00 GiB already allocated; 11.94 MiB free; 3.13 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
c260beb5,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 11, 'num_CL': 4, 'size_CL': 15, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 70.00 MiB (GPU 0; 23.65 GiB total capacity; 3.00 GiB already allocated; 11.94 MiB free; 3.13 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
53d38d1d,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 34, 'num_CL': 4, 'size_CL': 22, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 114.00 MiB (GPU 0; 23.65 GiB total capacity; 2.79 GiB already allocated; 99.94 MiB free; 3.04 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
7dc35f50,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 33, 'num_CL': 4, 'size_CL': 29, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 196.00 MiB (GPU 0; 23.65 GiB total capacity; 2.79 GiB already allocated; 99.94 MiB free; 3.04 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
961e9e29,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 29, 'num_CL': 4, 'size_CL': 27, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 170.00 MiB (GPU 0; 23.65 GiB total capacity; 2.79 GiB already allocated; 99.94 MiB free; 3.04 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
c704582f,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 14, 'num_CL': 4, 'size_CL': 23, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 172.00 MiB (GPU 0; 23.65 GiB total capacity; 2.79 GiB already allocated; 99.94 MiB free; 3.04 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
234b0afa,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 26, 'num_CL': 4, 'size_CL': 31, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 228.00 MiB (GPU 0; 23.65 GiB total capacity; 2.79 GiB already allocated; 99.94 MiB free; 3.04 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
fb5102b1,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 36, 'num_CL': 3, 'size_CL': 18, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 102.00 MiB (GPU 0; 23.65 GiB total capacity; 2.95 GiB already allocated; 99.94 MiB free; 3.04 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
1043ecd0,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 28, 'num_CL': 4, 'size_CL': 14, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 46.00 MiB (GPU 0; 23.65 GiB total capacity; 3.02 GiB already allocated; 7.94 MiB free; 3.13 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
861e9749,"{'batch_size': 64, 'num_HL': 6, 'latent_dim': 33, 'num_CL': 4, 'size_CL': 20, 'kernel': 2, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 162.00 MiB (GPU 0; 23.65 GiB total capacity; 2.79 GiB already allocated; 99.94 MiB free; 3.04 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
189c43fa,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 28, 'num_CL': 4, 'size_CL': 19, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 112.00 MiB (GPU 0; 23.65 GiB total capacity; 2.79 GiB already allocated; 99.94 MiB free; 3.04 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
5b8596ec,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 34, 'num_CL': 4, 'size_CL': 26, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 158.00 MiB (GPU 0; 23.65 GiB total capacity; 2.79 GiB already allocated; 99.94 MiB free; 3.04 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
f12f7723,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 35, 'num_CL': 4, 'size_CL': 26, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 384.00 MiB (GPU 0; 23.65 GiB total capacity; 3.95 GiB already allocated; 113.94 MiB free; 5.39 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
64b677d6,"{'batch_size': 64, 'num_HL': 4, 'latent_dim': 32, 'num_CL': 4, 'size_CL': 28, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 138.00 MiB (GPU 0; 23.65 GiB total capacity; 2.46 GiB already allocated; 115.94 MiB free; 3.04 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 94, in _init_group
    state['exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
4d636bcb,"{'batch_size': 128, 'num_HL': 5, 'latent_dim': 34, 'num_CL': 2, 'size_CL': 21, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 52.00 MiB (GPU 0; 23.65 GiB total capacity; 3.59 GiB already allocated; 13.94 MiB free; 3.81 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
3a97d87d,"{'batch_size': 64, 'num_HL': 5, 'latent_dim': 34, 'num_CL': 2, 'size_CL': 21, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 170.00 MiB (GPU 0; 23.65 GiB total capacity; 2.67 GiB already allocated; 55.94 MiB free; 3.09 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
459aa4b1,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 36, 'num_CL': 2, 'size_CL': 22, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 156.00 MiB (GPU 0; 23.65 GiB total capacity; 2.44 GiB already allocated; 29.94 MiB free; 3.11 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
f606d109,"{'batch_size': 128, 'num_HL': 6, 'latent_dim': 30, 'num_CL': 2, 'size_CL': 23, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 212.00 MiB (GPU 0; 23.65 GiB total capacity; 3.87 GiB already allocated; 41.94 MiB free; 4.16 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
5f10e717,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 36, 'num_CL': 3, 'size_CL': 21, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 308.00 MiB (GPU 0; 23.65 GiB total capacity; 2.75 GiB already allocated; 33.94 MiB free; 3.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
2151fb5e,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 34, 'num_CL': 4, 'size_CL': 24, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 348.00 MiB (GPU 0; 23.65 GiB total capacity; 3.73 GiB already allocated; 7.94 MiB free; 4.84 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
daaa5fca,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 31, 'num_CL': 4, 'size_CL': 21, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 306.00 MiB (GPU 0; 23.65 GiB total capacity; 2.24 GiB already allocated; 93.94 MiB free; 2.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
3c92041d,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 29, 'num_CL': 4, 'size_CL': 19, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 276.00 MiB (GPU 0; 23.65 GiB total capacity; 2.58 GiB already allocated; 263.94 MiB free; 3.55 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
5797fc29,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 30, 'num_CL': 4, 'size_CL': 22, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 322.00 MiB (GPU 0; 23.65 GiB total capacity; 2.08 GiB already allocated; 35.94 MiB free; 2.87 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
4011dc6c,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 35, 'num_CL': 4, 'size_CL': 20, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 194.00 MiB (GPU 0; 23.65 GiB total capacity; 2.98 GiB already allocated; 73.94 MiB free; 3.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
08c74f15,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 36, 'num_CL': 4, 'size_CL': 23, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 334.00 MiB (GPU 0; 23.65 GiB total capacity; 2.55 GiB already allocated; 313.94 MiB free; 3.31 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
faffcbe6,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 31, 'num_CL': 4, 'size_CL': 19, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 278.00 MiB (GPU 0; 23.65 GiB total capacity; 2.31 GiB already allocated; 17.94 MiB free; 3.31 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
1b22bddf,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 35, 'num_CL': 4, 'size_CL': 19, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 278.00 MiB (GPU 0; 23.65 GiB total capacity; 2.31 GiB already allocated; 195.94 MiB free; 3.14 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
ae04acc6,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 34, 'num_CL': 4, 'size_CL': 20, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 294.00 MiB (GPU 0; 23.65 GiB total capacity; 2.51 GiB already allocated; 201.94 MiB free; 3.15 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
5dade8fa,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 33, 'num_CL': 4, 'size_CL': 16, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 156.00 MiB (GPU 0; 23.65 GiB total capacity; 2.14 GiB already allocated; 141.94 MiB free; 3.14 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
de27ec35,"{'batch_size': 64, 'num_HL': 8, 'latent_dim': 32, 'num_CL': 4, 'size_CL': 23, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 116.00 MiB (GPU 0; 23.65 GiB total capacity; 4.09 GiB already allocated; 109.94 MiB free; 4.17 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 92, in _init_group
    state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
815dcc51,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 35, 'num_CL': 4, 'size_CL': 18, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 262.00 MiB (GPU 0; 23.65 GiB total capacity; 2.37 GiB already allocated; 89.94 MiB free; 3.08 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
d1d36b5a,"{'batch_size': 64, 'num_HL': 7, 'latent_dim': 33, 'num_CL': 4, 'size_CL': 21, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 126.00 MiB (GPU 0; 23.65 GiB total capacity; 3.84 GiB already allocated; 27.94 MiB free; 4.24 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
f14ccab3,"{'batch_size': 64, 'num_HL': 5, 'latent_dim': 31, 'num_CL': 4, 'size_CL': 19, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 82.00 MiB (GPU 0; 23.65 GiB total capacity; 2.95 GiB already allocated; 17.94 MiB free; 3.08 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
9f792895,"{'batch_size': 64, 'num_HL': 6, 'latent_dim': 28, 'num_CL': 3, 'size_CL': 16, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 234.00 MiB (GPU 0; 23.65 GiB total capacity; 3.02 GiB already allocated; 137.94 MiB free; 3.49 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
19a0966a,"{'batch_size': 64, 'num_HL': 4, 'latent_dim': 33, 'num_CL': 4, 'size_CL': 21, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 154.00 MiB (GPU 0; 23.65 GiB total capacity; 3.02 GiB already allocated; 95.94 MiB free; 3.54 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
580cf4ac,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 31, 'num_CL': 4, 'size_CL': 24, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 358.00 MiB (GPU 0; 23.65 GiB total capacity; 2.76 GiB already allocated; 89.94 MiB free; 3.77 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
7746e2b8,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 30, 'num_CL': 4, 'size_CL': 23, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 1, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 1, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 338.00 MiB (GPU 0; 23.65 GiB total capacity; 3.54 GiB already allocated; 139.94 MiB free; 4.08 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
dace70ae,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 30, 'num_CL': 3, 'size_CL': 22, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 216.00 MiB (GPU 0; 23.65 GiB total capacity; 3.18 GiB already allocated; 57.94 MiB free; 4.45 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
882da40d,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 29, 'num_CL': 3, 'size_CL': 25, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 366.00 MiB (GPU 0; 23.65 GiB total capacity; 2.56 GiB already allocated; 307.94 MiB free; 3.19 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
c620ff5c,"{'batch_size': 64, 'num_HL': 4, 'latent_dim': 35, 'num_CL': 4, 'size_CL': 24, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 200.00 MiB (GPU 0; 23.65 GiB total capacity; 3.09 GiB already allocated; 109.94 MiB free; 3.38 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
61c02a2b,"{'batch_size': 64, 'num_HL': 6, 'latent_dim': 17, 'num_CL': 4, 'size_CL': 21, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 170.00 MiB (GPU 0; 23.65 GiB total capacity; 3.12 GiB already allocated; 109.94 MiB free; 3.38 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
519d9aef,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 25, 'num_CL': 4, 'size_CL': 23, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 334.00 MiB (GPU 0; 23.65 GiB total capacity; 3.48 GiB already allocated; 155.94 MiB free; 4.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
f52bfa87,"{'batch_size': 64, 'num_HL': 5, 'latent_dim': 26, 'num_CL': 4, 'size_CL': 18, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 264.00 MiB (GPU 0; 23.65 GiB total capacity; 3.16 GiB already allocated; 143.94 MiB free; 4.44 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
a4c6dd78,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 21, 'num_CL': 4, 'size_CL': 25, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 370.00 MiB (GPU 0; 23.65 GiB total capacity; 3.27 GiB already allocated; 7.94 MiB free; 4.27 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
b09497a7,"{'batch_size': 64, 'num_HL': 4, 'latent_dim': 24, 'num_CL': 3, 'size_CL': 27, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 130.00 MiB (GPU 0; 23.65 GiB total capacity; 1.83 GiB already allocated; 61.94 MiB free; 2.13 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
506d43a7,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 28, 'num_CL': 3, 'size_CL': 19, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 114.00 MiB (GPU 0; 23.65 GiB total capacity; 1.79 GiB already allocated; 59.94 MiB free; 2.13 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
b472f873,"{'batch_size': 64, 'num_HL': 7, 'latent_dim': 25, 'num_CL': 3, 'size_CL': 24, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 168.00 MiB (GPU 0; 23.65 GiB total capacity; 4.09 GiB already allocated; 67.94 MiB free; 4.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 92, in _init_group
    state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
9e19134d,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 27, 'num_CL': 3, 'size_CL': 21, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 314.00 MiB (GPU 0; 23.65 GiB total capacity; 1.36 GiB already allocated; 297.94 MiB free; 1.90 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
36f67faf,"{'batch_size': 64, 'num_HL': 8, 'latent_dim': 26, 'num_CL': 3, 'size_CL': 27, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.65 GiB total capacity; 1.79 GiB already allocated; 1.94 MiB free; 2.19 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 82, in __one_epoch
    loss, loss_components = self.model(inputs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 40, in forward
    latent = self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py"", line 114, in forward
    return F.linear(input, self.weight, self.bias)
"
0f7446f2,"{'batch_size': 128, 'num_HL': 7, 'latent_dim': 26, 'num_CL': 3, 'size_CL': 24, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 234.00 MiB (GPU 0; 23.65 GiB total capacity; 4.87 GiB already allocated; 189.94 MiB free; 5.28 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
b71c6904,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 27, 'num_CL': 3, 'size_CL': 22, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 328.00 MiB (GPU 0; 23.65 GiB total capacity; 1.47 GiB already allocated; 323.94 MiB free; 1.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
97fb1b97,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 19, 'num_CL': 3, 'size_CL': 23, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 126.00 MiB (GPU 0; 23.65 GiB total capacity; 1.60 GiB already allocated; 121.94 MiB free; 1.78 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
f8888ace,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 23, 'num_CL': 3, 'size_CL': 28, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 186.00 MiB (GPU 0; 23.65 GiB total capacity; 1.64 GiB already allocated; 77.94 MiB free; 1.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
5b7d387a,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 24, 'num_CL': 3, 'size_CL': 22, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 116.00 MiB (GPU 0; 23.65 GiB total capacity; 1.13 GiB already allocated; 77.94 MiB free; 1.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
938c6210,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 28, 'num_CL': 3, 'size_CL': 24, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 140.00 MiB (GPU 0; 23.65 GiB total capacity; 1.37 GiB already allocated; 77.94 MiB free; 1.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
eae1887f,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 25, 'num_CL': 3, 'size_CL': 26, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 160.00 MiB (GPU 0; 23.65 GiB total capacity; 1.58 GiB already allocated; 77.94 MiB free; 1.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
eb7107e3,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 27, 'num_CL': 3, 'size_CL': 21, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 106.00 MiB (GPU 0; 23.65 GiB total capacity; 1.14 GiB already allocated; 77.94 MiB free; 1.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
1d67b6c9,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 29, 'num_CL': 3, 'size_CL': 25, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 148.00 MiB (GPU 0; 23.65 GiB total capacity; 1.46 GiB already allocated; 77.94 MiB free; 1.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
c8abe178,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 26, 'num_CL': 3, 'size_CL': 20, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 23.65 GiB total capacity; 1.03 GiB already allocated; 77.94 MiB free; 1.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
be50383a,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 28, 'num_CL': 3, 'size_CL': 23, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 126.00 MiB (GPU 0; 23.65 GiB total capacity; 1.24 GiB already allocated; 77.94 MiB free; 1.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
61fc96d9,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 29, 'num_CL': 3, 'size_CL': 22, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 116.00 MiB (GPU 0; 23.65 GiB total capacity; 1.14 GiB already allocated; 77.94 MiB free; 1.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
c19a9f8f,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 20, 'num_CL': 3, 'size_CL': 21, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 104.00 MiB (GPU 0; 23.65 GiB total capacity; 1.14 GiB already allocated; 77.94 MiB free; 1.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
9f46bd86,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 22, 'num_CL': 3, 'size_CL': 19, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 114.00 MiB (GPU 0; 23.65 GiB total capacity; 1.39 GiB already allocated; 79.94 MiB free; 1.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
87d507fd,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 26, 'num_CL': 3, 'size_CL': 24, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 136.00 MiB (GPU 0; 23.65 GiB total capacity; 1.35 GiB already allocated; 77.94 MiB free; 1.82 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
d42541e5,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 25, 'num_CL': 3, 'size_CL': 29, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 202.00 MiB (GPU 0; 23.65 GiB total capacity; 1.60 GiB already allocated; 151.94 MiB free; 1.75 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
22db76fb,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 27, 'num_CL': 3, 'size_CL': 20, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 126.00 MiB (GPU 0; 23.65 GiB total capacity; 1.53 GiB already allocated; 27.94 MiB free; 1.87 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
cf32229f,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 30, 'num_CL': 3, 'size_CL': 22, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 116.00 MiB (GPU 0; 23.65 GiB total capacity; 1.14 GiB already allocated; 25.94 MiB free; 1.87 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
6d81f2d5,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 29, 'num_CL': 3, 'size_CL': 26, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 23.65 GiB total capacity; 1.75 GiB already allocated; 9.94 MiB free; 1.88 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 94, in _init_group
    state['exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
ec385da1,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 28, 'num_CL': 3, 'size_CL': 23, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 126.00 MiB (GPU 0; 23.65 GiB total capacity; 1.24 GiB already allocated; 117.94 MiB free; 1.78 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
8d4d4676,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 23, 'num_CL': 3, 'size_CL': 27, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 172.00 MiB (GPU 0; 23.65 GiB total capacity; 1.36 GiB already allocated; 151.94 MiB free; 1.75 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
59a3ac61,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 30, 'num_CL': 3, 'size_CL': 20, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 298.00 MiB (GPU 0; 23.65 GiB total capacity; 1.25 GiB already allocated; 137.94 MiB free; 1.75 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
8c9aac43,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 28, 'num_CL': 3, 'size_CL': 25, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 148.00 MiB (GPU 0; 23.65 GiB total capacity; 1.32 GiB already allocated; 141.94 MiB free; 1.75 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
c55a1026,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 31, 'num_CL': 3, 'size_CL': 22, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 116.00 MiB (GPU 0; 23.65 GiB total capacity; 1.14 GiB already allocated; 25.94 MiB free; 1.86 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
5e07088f,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 10, 'num_CL': 3, 'size_CL': 21, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 312.00 MiB (GPU 0; 23.65 GiB total capacity; 1.67 GiB already allocated; 135.94 MiB free; 2.00 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
cbcec65b,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 24, 'num_CL': 3, 'size_CL': 23, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 126.00 MiB (GPU 0; 23.65 GiB total capacity; 1.36 GiB already allocated; 123.94 MiB free; 2.01 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
8ad4a72e,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 25, 'num_CL': 3, 'size_CL': 18, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 266.00 MiB (GPU 0; 23.65 GiB total capacity; 1.30 GiB already allocated; 121.94 MiB free; 2.01 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
8bbbfd08,"{'batch_size': 64, 'num_HL': 6, 'latent_dim': 30, 'num_CL': 3, 'size_CL': 27, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 116.00 MiB (GPU 0; 23.65 GiB total capacity; 1.82 GiB already allocated; 71.94 MiB free; 2.06 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
bfd92ac7,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 31, 'num_CL': 3, 'size_CL': 25, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 148.00 MiB (GPU 0; 23.65 GiB total capacity; 1.61 GiB already allocated; 47.94 MiB free; 2.08 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
9a4c0e14,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 21, 'num_CL': 3, 'size_CL': 21, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 104.00 MiB (GPU 0; 23.65 GiB total capacity; 1.68 GiB already allocated; 41.94 MiB free; 2.08 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
1bb23b9a,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 23, 'num_CL': 3, 'size_CL': 22, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 152.00 MiB (GPU 0; 23.65 GiB total capacity; 1.85 GiB already allocated; 49.94 MiB free; 2.08 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
8eee371f,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 27, 'num_CL': 3, 'size_CL': 24, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 354.00 MiB (GPU 0; 23.65 GiB total capacity; 3.09 GiB already allocated; 41.94 MiB free; 4.20 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
b41e1e4f,"{'batch_size': 64, 'num_HL': 8, 'latent_dim': 30, 'num_CL': 3, 'size_CL': 18, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 136.00 MiB (GPU 0; 23.65 GiB total capacity; 4.01 GiB already allocated; 37.94 MiB free; 4.20 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
d16b4b1f,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 26, 'num_CL': 3, 'size_CL': 20, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 296.00 MiB (GPU 0; 23.65 GiB total capacity; 1.53 GiB already allocated; 35.94 MiB free; 2.08 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
681d3a52,"{'batch_size': 128, 'num_HL': 2, 'latent_dim': 26, 'num_CL': 3, 'size_CL': 24, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 136.00 MiB (GPU 0; 23.65 GiB total capacity; 1.61 GiB already allocated; 35.94 MiB free; 2.08 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
9907cc9a,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 24, 'num_CL': 4, 'size_CL': 26, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 382.00 MiB (GPU 0; 23.65 GiB total capacity; 2.69 GiB already allocated; 303.94 MiB free; 3.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
750ba077,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 31, 'num_CL': 4, 'size_CL': 20, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 294.00 MiB (GPU 0; 23.65 GiB total capacity; 1.81 GiB already allocated; 11.94 MiB free; 2.37 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
b61c9714,"{'batch_size': 64, 'num_HL': 5, 'latent_dim': 33, 'num_CL': 4, 'size_CL': 20, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 90.00 MiB (GPU 0; 23.65 GiB total capacity; 3.27 GiB already allocated; 55.94 MiB free; 3.45 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
e9de5597,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 34, 'num_CL': 4, 'size_CL': 22, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 150.00 MiB (GPU 0; 23.65 GiB total capacity; 1.97 GiB already allocated; 31.94 MiB free; 2.35 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
3650f70d,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 29, 'num_CL': 4, 'size_CL': 18, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 262.00 MiB (GPU 0; 23.65 GiB total capacity; 1.80 GiB already allocated; 167.94 MiB free; 2.21 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
40f2e5ca,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 29, 'num_CL': 4, 'size_CL': 19, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 284.00 MiB (GPU 0; 23.65 GiB total capacity; 1.76 GiB already allocated; 157.94 MiB free; 2.22 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
f3e2d47b,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 32, 'num_CL': 3, 'size_CL': 22, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 326.00 MiB (GPU 0; 23.65 GiB total capacity; 1.79 GiB already allocated; 135.94 MiB free; 2.24 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
96f61615,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 31, 'num_CL': 4, 'size_CL': 20, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 194.00 MiB (GPU 0; 23.65 GiB total capacity; 2.98 GiB already allocated; 139.94 MiB free; 4.20 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
759bfed1,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 35, 'num_CL': 4, 'size_CL': 17, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 254.00 MiB (GPU 0; 23.65 GiB total capacity; 1.45 GiB already allocated; 141.94 MiB free; 2.23 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
da3b02e9,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 29, 'num_CL': 3, 'size_CL': 21, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 310.00 MiB (GPU 0; 23.65 GiB total capacity; 2.45 GiB already allocated; 139.94 MiB free; 3.45 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
73a08a58,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 33, 'num_CL': 4, 'size_CL': 20, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 296.00 MiB (GPU 0; 23.65 GiB total capacity; 1.52 GiB already allocated; 143.94 MiB free; 2.24 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
6cab639a,"{'batch_size': 64, 'num_HL': 5, 'latent_dim': 16, 'num_CL': 3, 'size_CL': 21, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 314.00 MiB (GPU 0; 23.65 GiB total capacity; 3.58 GiB already allocated; 205.94 MiB free; 4.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
56d2bc68,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 31, 'num_CL': 3, 'size_CL': 24, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 182.00 MiB (GPU 0; 23.65 GiB total capacity; 2.38 GiB already allocated; 9.94 MiB free; 2.93 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
ca1295e2,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 30, 'num_CL': 3, 'size_CL': 23, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 168.00 MiB (GPU 0; 23.65 GiB total capacity; 2.89 GiB already allocated; 105.94 MiB free; 3.15 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
2c1e2954,"{'batch_size': 64, 'num_HL': 6, 'latent_dim': 26, 'num_CL': 4, 'size_CL': 19, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 140.00 MiB (GPU 0; 23.65 GiB total capacity; 3.06 GiB already allocated; 107.94 MiB free; 3.14 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
ef68dfc5,"{'batch_size': 64, 'num_HL': 7, 'latent_dim': 34, 'num_CL': 4, 'size_CL': 20, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 114.00 MiB (GPU 0; 23.65 GiB total capacity; 2.80 GiB already allocated; 105.94 MiB free; 2.96 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    # If the reducer_validation_dataset_name is in the datasets and use_y is True,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 92, in _init_group
    state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
a5fbcf4b,"{'batch_size': 64, 'num_HL': 4, 'latent_dim': 30, 'num_CL': 4, 'size_CL': 17, 'kernel': 3, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 250.00 MiB (GPU 0; 23.65 GiB total capacity; 2.69 GiB already allocated; 117.94 MiB free; 3.50 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    config_to_execute.metadata = from_dict(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    # and the new suffix

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    # and the new suffix

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
5f141d3e,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 34, 'num_CL': 4, 'size_CL': 20, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 296.00 MiB (GPU 0; 23.65 GiB total capacity; 2.22 GiB already allocated; 195.94 MiB free; 2.86 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    config_to_execute.metadata = from_dict(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    # and the new suffix

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    # and the new suffix

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
43da30df,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 33, 'num_CL': 4, 'size_CL': 18, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 1}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 264.00 MiB (GPU 0; 23.65 GiB total capacity; 2.12 GiB already allocated; 191.94 MiB free; 2.87 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    config_to_execute.metadata = from_dict(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    # and the new suffix

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    # and the new suffix

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
94336bc1,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 34, 'num_CL': 4, 'size_CL': 20, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 294.00 MiB (GPU 0; 23.65 GiB total capacity; 2.51 GiB already allocated; 205.94 MiB free; 3.15 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    config_to_execute.metadata = from_dict(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    # and the new suffix

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    # and the new suffix

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
3dbff555,"{'batch_size': 64, 'num_HL': 8, 'latent_dim': 33, 'num_CL': 4, 'size_CL': 16, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 104.00 MiB (GPU 0; 23.65 GiB total capacity; 3.58 GiB already allocated; 59.94 MiB free; 3.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    config_to_execute.metadata = from_dict(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    # If the reducer_validation_dataset_name is in the datasets and use_y is True,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
db547522,"{'batch_size': 64, 'num_HL': 5, 'latent_dim': 34, 'num_CL': 4, 'size_CL': 21, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 100.00 MiB (GPU 0; 23.65 GiB total capacity; 4.25 GiB already allocated; 27.94 MiB free; 4.44 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    config_to_execute.metadata = from_dict(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    # If the reducer_validation_dataset_name is in the datasets and use_y is True,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
69c4348d,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 35, 'num_CL': 4, 'size_CL': 20, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 194.00 MiB (GPU 0; 23.65 GiB total capacity; 2.98 GiB already allocated; 41.94 MiB free; 3.86 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    config_to_execute.metadata = from_dict(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    # and the new suffix

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    # and the new suffix

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
b5a6a36e,"{'batch_size': 64, 'num_HL': 6, 'latent_dim': 35, 'num_CL': 4, 'size_CL': 24, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 222.00 MiB (GPU 0; 23.65 GiB total capacity; 3.86 GiB already allocated; 149.94 MiB free; 4.08 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    config_to_execute.metadata = from_dict(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    # If the reducer_validation_dataset_name is in the datasets and use_y is True,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 94, in _init_group
    state['exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
25f435ba,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 35, 'num_CL': 4, 'size_CL': 25, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 194.00 MiB (GPU 0; 23.65 GiB total capacity; 2.85 GiB already allocated; 119.94 MiB free; 3.06 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 61, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 58, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 127, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
2093cffb,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 33, 'num_CL': 4, 'size_CL': 25, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 364.00 MiB (GPU 0; 23.65 GiB total capacity; 2.89 GiB already allocated; 281.94 MiB free; 3.70 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    config_to_execute.metadata = from_dict(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    # and the new suffix

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    # and the new suffix

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
d681d75a,"{'batch_size': 64, 'num_HL': 4, 'latent_dim': 32, 'num_CL': 4, 'size_CL': 21, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 308.00 MiB (GPU 0; 23.65 GiB total capacity; 3.44 GiB already allocated; 297.94 MiB free; 4.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    config_to_execute.metadata = from_dict(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    # and the new suffix

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    # and the new suffix

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
5bd2005c,"{'batch_size': 64, 'num_HL': 7, 'latent_dim': 34, 'num_CL': 4, 'size_CL': 23, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 210.00 MiB (GPU 0; 23.65 GiB total capacity; 4.40 GiB already allocated; 91.94 MiB free; 4.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    config_to_execute.metadata = from_dict(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    # If the reducer_validation_dataset_name is in the datasets and use_y is True,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
ae0044e4,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 31, 'num_CL': 4, 'size_CL': 24, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 358.00 MiB (GPU 0; 23.65 GiB total capacity; 2.70 GiB already allocated; 279.94 MiB free; 3.52 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 61, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 58, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 153, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 153, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
bc35ae73,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 34, 'num_CL': 4, 'size_CL': 20, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 296.00 MiB (GPU 0; 23.65 GiB total capacity; 2.23 GiB already allocated; 91.94 MiB free; 2.70 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    config_to_execute.metadata = from_dict(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    # and the new suffix

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    # and the new suffix

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
fee1048f,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 36, 'num_CL': 4, 'size_CL': 28, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 182.00 MiB (GPU 0; 23.65 GiB total capacity; 2.16 GiB already allocated; 11.94 MiB free; 2.78 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    config_to_execute.metadata = from_dict(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    # If the reducer_validation_dataset_name is in the datasets and use_y is True,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
1e553499,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 36, 'num_CL': 4, 'size_CL': 27, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 226.00 MiB (GPU 0; 23.65 GiB total capacity; 2.37 GiB already allocated; 65.94 MiB free; 2.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    config_to_execute.metadata = from_dict(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    # If the reducer_validation_dataset_name is in the datasets and use_y is True,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
3cc8fd81,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 36, 'num_CL': 4, 'size_CL': 31, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 224.00 MiB (GPU 0; 23.65 GiB total capacity; 2.42 GiB already allocated; 7.94 MiB free; 2.78 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    config_to_execute.metadata = from_dict(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    # If the reducer_validation_dataset_name is in the datasets and use_y is True,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
76425afb,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 35, 'num_CL': 4, 'size_CL': 26, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 158.00 MiB (GPU 0; 23.65 GiB total capacity; 1.71 GiB already allocated; 11.94 MiB free; 2.78 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    config_to_execute.metadata = from_dict(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    # If the reducer_validation_dataset_name is in the datasets and use_y is True,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
e1bbea45,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 36, 'num_CL': 4, 'size_CL': 28, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 182.00 MiB (GPU 0; 23.65 GiB total capacity; 1.98 GiB already allocated; 9.94 MiB free; 2.78 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    config_to_execute.metadata = from_dict(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    # If the reducer_validation_dataset_name is in the datasets and use_y is True,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
9dfaf4af,"{'batch_size': 128, 'num_HL': 3, 'latent_dim': 35, 'num_CL': 4, 'size_CL': 26, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 210.00 MiB (GPU 0; 23.65 GiB total capacity; 2.20 GiB already allocated; 15.94 MiB free; 2.77 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    config_to_execute.metadata = from_dict(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    # If the reducer_validation_dataset_name is in the datasets and use_y is True,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
6cc22487,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 36, 'num_CL': 4, 'size_CL': 30, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 210.00 MiB (GPU 0; 23.65 GiB total capacity; 2.27 GiB already allocated; 7.94 MiB free; 2.78 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    config_to_execute.metadata = from_dict(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    # If the reducer_validation_dataset_name is in the datasets and use_y is True,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
acac2cdf,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 34, 'num_CL': 4, 'size_CL': 25, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 146.00 MiB (GPU 0; 23.65 GiB total capacity; 1.86 GiB already allocated; 11.94 MiB free; 2.78 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    config_to_execute.metadata = from_dict(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    # If the reducer_validation_dataset_name is in the datasets and use_y is True,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
0cecba6d,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 33, 'num_CL': 4, 'size_CL': 26, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 382.00 MiB (GPU 0; 23.65 GiB total capacity; 2.69 GiB already allocated; 233.94 MiB free; 3.31 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    config_to_execute.metadata = from_dict(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    # and the new suffix

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    # and the new suffix

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
c1a38564,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 34, 'num_CL': 4, 'size_CL': 25, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 194.00 MiB (GPU 0; 23.65 GiB total capacity; 2.85 GiB already allocated; 101.94 MiB free; 3.28 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    config_to_execute.metadata = from_dict(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    # If the reducer_validation_dataset_name is in the datasets and use_y is True,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
e2b5f5e6,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 35, 'num_CL': 4, 'size_CL': 26, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 158.00 MiB (GPU 0; 23.65 GiB total capacity; 1.86 GiB already allocated; 101.94 MiB free; 2.93 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    config_to_execute.metadata = from_dict(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    # If the reducer_validation_dataset_name is in the datasets and use_y is True,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
1e54138b,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 36, 'num_CL': 4, 'size_CL': 29, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 260.00 MiB (GPU 0; 23.65 GiB total capacity; 2.48 GiB already allocated; 201.94 MiB free; 2.81 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    config_to_execute.metadata = from_dict(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    # If the reducer_validation_dataset_name is in the datasets and use_y is True,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 94, in _init_group
    state['exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
8461c43b,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 35, 'num_CL': 4, 'size_CL': 24, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 352.00 MiB (GPU 0; 23.65 GiB total capacity; 2.38 GiB already allocated; 179.94 MiB free; 3.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    config_to_execute.metadata = from_dict(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    # and the new suffix

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    # and the new suffix

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
815bbf1f,"{'batch_size': 64, 'num_HL': 5, 'latent_dim': 34, 'num_CL': 4, 'size_CL': 26, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 152.00 MiB (GPU 0; 23.65 GiB total capacity; 3.16 GiB already allocated; 37.94 MiB free; 3.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    config_to_execute.metadata = from_dict(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    # If the reducer_validation_dataset_name is in the datasets and use_y is True,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 92, in _init_group
    state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
846b4e3a,"{'batch_size': 128, 'num_HL': 4, 'latent_dim': 36, 'num_CL': 4, 'size_CL': 27, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 254.00 MiB (GPU 0; 23.65 GiB total capacity; 4.73 GiB already allocated; 11.94 MiB free; 4.96 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    config_to_execute.metadata = from_dict(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    # If the reducer_validation_dataset_name is in the datasets and use_y is True,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
335cff14,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 33, 'num_CL': 4, 'size_CL': 25, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 364.00 MiB (GPU 0; 23.65 GiB total capacity; 2.89 GiB already allocated; 309.94 MiB free; 3.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    config_to_execute.metadata = from_dict(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    # and the new suffix

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    # and the new suffix

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
44163f48,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 36, 'num_CL': 4, 'size_CL': 25, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 364.00 MiB (GPU 0; 23.65 GiB total capacity; 2.89 GiB already allocated; 177.94 MiB free; 3.92 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 61, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 58, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 153, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 153, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
ec064526,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 34, 'num_CL': 4, 'size_CL': 28, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 414.00 MiB (GPU 0; 23.65 GiB total capacity; 2.62 GiB already allocated; 89.94 MiB free; 3.30 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    config_to_execute.metadata = from_dict(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    # and the new suffix

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    # and the new suffix

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
306b1d53,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 35, 'num_CL': 4, 'size_CL': 24, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 354.00 MiB (GPU 0; 23.65 GiB total capacity; 3.05 GiB already allocated; 271.94 MiB free; 3.91 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    config_to_execute.metadata = from_dict(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    # and the new suffix

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    # and the new suffix

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
e7d21069,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 33, 'num_CL': 4, 'size_CL': 30, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 278.00 MiB (GPU 0; 23.65 GiB total capacity; 3.05 GiB already allocated; 271.94 MiB free; 3.91 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    config_to_execute.metadata = from_dict(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    # If the reducer_validation_dataset_name is in the datasets and use_y is True,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
66c84dfa,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 18, 'num_CL': 4, 'size_CL': 25, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 366.00 MiB (GPU 0; 23.65 GiB total capacity; 2.53 GiB already allocated; 157.94 MiB free; 3.41 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    config_to_execute.metadata = from_dict(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    # and the new suffix

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    # and the new suffix

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
76618d0c,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 34, 'num_CL': 4, 'size_CL': 26, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 382.00 MiB (GPU 0; 23.65 GiB total capacity; 3.88 GiB already allocated; 163.94 MiB free; 5.05 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    config_to_execute.metadata = from_dict(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    # and the new suffix

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    # and the new suffix

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
7091760f,"{'batch_size': 64, 'num_HL': 3, 'latent_dim': 36, 'num_CL': 4, 'size_CL': 23, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 164.00 MiB (GPU 0; 23.65 GiB total capacity; 274.67 MiB already allocated; 121.94 MiB free; 278.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 61, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 58, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 127, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
ce8cdbfc,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 34, 'num_CL': 4, 'size_CL': 25, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 1, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 146.00 MiB (GPU 0; 23.65 GiB total capacity; 331.97 MiB already allocated; 5.94 MiB free; 354.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 61, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 58, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 127, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
86a049ec,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 31, 'num_CL': 4, 'size_CL': 22, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 114.00 MiB (GPU 0; 23.65 GiB total capacity; 263.97 MiB already allocated; 3.94 MiB free; 356.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 61, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 58, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 127, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
659fb7c8,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 33, 'num_CL': 4, 'size_CL': 22, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 114.00 MiB (GPU 0; 23.65 GiB total capacity; 264.06 MiB already allocated; 3.94 MiB free; 356.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 61, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 58, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 127, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
4ae065eb,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 32, 'num_CL': 4, 'size_CL': 21, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 104.00 MiB (GPU 0; 23.65 GiB total capacity; 243.63 MiB already allocated; 3.94 MiB free; 356.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 61, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 58, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 127, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 84, in __one_epoch
    loss.backward()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/_tensor.py"", line 487, in backward
    torch.autograd.backward(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
"
6cd34752,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 30, 'num_CL': 4, 'size_CL': 20, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 298.00 MiB (GPU 0; 23.65 GiB total capacity; 1.23 GiB already allocated; 271.94 MiB free; 1.38 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 61, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 58, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 153, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 153, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
7f1131b5,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 33, 'num_CL': 4, 'size_CL': 21, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 104.00 MiB (GPU 0; 23.65 GiB total capacity; 1.32 GiB already allocated; 103.94 MiB free; 1.54 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 61, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 58, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 127, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
ffd84472,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 3, 'num_CL': 4, 'size_CL': 29, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 196.00 MiB (GPU 0; 23.65 GiB total capacity; 1.35 GiB already allocated; 17.94 MiB free; 1.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 61, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 58, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 127, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 132, in step
    self._init_group(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 94, in _init_group
    state['exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)
"
bda64732,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 30, 'num_CL': 4, 'size_CL': 23, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 124.00 MiB (GPU 0; 23.65 GiB total capacity; 1.10 GiB already allocated; 13.94 MiB free; 1.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 61, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 58, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 127, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
151930e4,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 31, 'num_CL': 4, 'size_CL': 22, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 326.00 MiB (GPU 0; 23.65 GiB total capacity; 1.77 GiB already allocated; 199.94 MiB free; 2.36 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    config_to_execute.metadata = from_dict(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    # and the new suffix

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    # and the new suffix

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
391a9e7d,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 29, 'num_CL': 4, 'size_CL': 18, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 23.65 GiB total capacity; 1.03 GiB already allocated; 207.94 MiB free; 1.25 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 61, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 58, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 153, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 153, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
afd9e760,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 31, 'num_CL': 4, 'size_CL': 22, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 114.00 MiB (GPU 0; 23.65 GiB total capacity; 1.01 GiB already allocated; 99.94 MiB free; 1.36 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 61, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 58, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 127, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
61d32600,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 32, 'num_CL': 4, 'size_CL': 19, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 276.00 MiB (GPU 0; 23.65 GiB total capacity; 1.94 GiB already allocated; 61.94 MiB free; 2.41 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    config_to_execute.metadata = from_dict(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    # and the new suffix

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    # and the new suffix

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
c1ad92b1,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 30, 'num_CL': 4, 'size_CL': 24, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 134.00 MiB (GPU 0; 23.65 GiB total capacity; 1.20 GiB already allocated; 1.94 MiB free; 1.41 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 61, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 58, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 127, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
352a2a47,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 35, 'num_CL': 4, 'size_CL': 27, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 170.00 MiB (GPU 0; 23.65 GiB total capacity; 1.68 GiB already allocated; 3.94 MiB free; 2.41 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    config_to_execute.metadata = from_dict(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    # If the reducer_validation_dataset_name is in the datasets and use_y is True,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
38fb2e35,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 31, 'num_CL': 4, 'size_CL': 32, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 238.00 MiB (GPU 0; 23.65 GiB total capacity; 2.11 GiB already allocated; 23.94 MiB free; 2.47 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    config_to_execute.metadata = from_dict(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    # If the reducer_validation_dataset_name is in the datasets and use_y is True,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
a955fbc5,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 34, 'num_CL': 4, 'size_CL': 20, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 94.00 MiB (GPU 0; 23.65 GiB total capacity; 1.11 GiB already allocated; 25.94 MiB free; 1.33 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 61, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 58, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 127, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
791218b9,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 36, 'num_CL': 4, 'size_CL': 23, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 124.00 MiB (GPU 0; 23.65 GiB total capacity; 1.10 GiB already allocated; 29.94 MiB free; 1.33 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 61, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 58, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 127, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 505, in _multi_tensor_adam
    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
"
37d3c001,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 33, 'num_CL': 4, 'size_CL': 26, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 382.00 MiB (GPU 0; 23.65 GiB total capacity; 2.69 GiB already allocated; 331.94 MiB free; 3.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    config_to_execute.metadata = from_dict(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    # and the new suffix

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    # and the new suffix

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
4e05d785,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 32, 'num_CL': 4, 'size_CL': 24, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 134.00 MiB (GPU 0; 23.65 GiB total capacity; 1.72 GiB already allocated; 29.94 MiB free; 2.47 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    config_to_execute.metadata = from_dict(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    # If the reducer_validation_dataset_name is in the datasets and use_y is True,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 141, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 281, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 507, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
ffff17d4,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 35, 'num_CL': 4, 'size_CL': 28, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 410.00 MiB (GPU 0; 23.65 GiB total capacity; 3.02 GiB already allocated; 213.94 MiB free; 3.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 61, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 58, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 153, in do_reduce
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 153, in <dictcomp>
    {dset_name: transformer(datasets[dset_name]) for dset_name in apply_only_in}

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
5e0d3f71,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 34, 'num_CL': 4, 'size_CL': 23, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 338.00 MiB (GPU 0; 23.65 GiB total capacity; 2.23 GiB already allocated; 221.94 MiB free; 3.30 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    config_to_execute.metadata = from_dict(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    # and the new suffix

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    # and the new suffix

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
3a21c1a1,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 33, 'num_CL': 4, 'size_CL': 23, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'torch.cuda.OutOfMemoryError'>,CUDA out of memory. Tried to allocate 334.00 MiB (GPU 0; 23.65 GiB total capacity; 2.55 GiB already allocated; 309.94 MiB free; 3.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF,"  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 56, in default_objective_function
    config_to_execute.metadata = from_dict(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 57, in h_search_unit
    # Run the experiment

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in do_reduce
    # and the new suffix

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 147, in <dictcomp>
    # and the new suffix

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/datasets/multimodal/transformer.py"", line 523, in __call__
    new_X = window_transform.the_transform.transform(X=X)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 328, in transform
    return self.model.encode(in_tensor).cpu().detach().numpy()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/topological_ae.py"", line 80, in encode
    return self.autoencoder.encode(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/estimators/ae/torch/models/topological_ae/model_submodules.py"", line 447, in encode
    return self.encoder(x)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/container.py"", line 217, in forward
    input = module(input)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py"", line 103, in forward
    return F.relu(input, inplace=self.inplace)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/functional.py"", line 1457, in relu
    result = torch.relu(input)
"
096ab23d,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 36, 'num_CL': 4, 'size_CL': 25, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'RuntimeError'>,"CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 61, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 58, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 127, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
a23dcf1d,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 35, 'num_CL': 4, 'size_CL': 26, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'RuntimeError'>,"CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 61, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 58, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 127, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
7d857f32,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 32, 'num_CL': 4, 'size_CL': 22, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'RuntimeError'>,"CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 61, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 58, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 127, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
500a9b10,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 34, 'num_CL': 4, 'size_CL': 23, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'RuntimeError'>,"CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 61, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 58, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 127, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
d4ef029c,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 33, 'num_CL': 4, 'size_CL': 24, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'RuntimeError'>,"CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 61, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 58, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 127, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
1d5aad15,"{'batch_size': 64, 'num_HL': 2, 'latent_dim': 35, 'num_CL': 4, 'size_CL': 21, 'kernel': 4, 'MC-red_dataset-kuhar.standartized_balanced[train]': 0, 'MC-red_dataset-motionsense.standartized_balanced[train]': 0, 'MC-red_dataset-uci.standartized_balanced[train]': 0, 'MC-red_dataset-wisdm.standartized_balanced[train]': 1, 'MC-red_dataset-realworld_thigh.standartized_balanced[train]': 0, 'MC-red_dataset-realworld_waist.standartized_balanced[train]': 0}",<class 'RuntimeError'>,"CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hs_objective_function.py"", line 61, in default_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 58, in h_search_unit
    experiment_result = run_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_experiment.py"", line 16, in run_experiment
    return functions[config_to_execute.metadata.experiment_type](

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_custom_experiment.py"", line 168, in run_custom_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 127, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 144, in fit
    self.model = self.model.to(self.cuda_device)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1145, in to
    return self._apply(convert)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 797, in _apply
    module._apply(fn)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 820, in _apply
    param_applied = fn(param)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1143, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
"
