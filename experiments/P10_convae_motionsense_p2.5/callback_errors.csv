trial_id,config,error_type,error_message,error_traceback
8efdfb43,"{'batch_size': 64, 'num_CL': 4, 'size_CL': 32, 'kernel': 3, 'num_HL': 3, 'latent_dim': 8, 'opt_lr': 0.00036618717502480863, 'opt_wd': 2.158859847918173e-07}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacty of 79.15 GiB of which 91.25 MiB is free. Process 1885097 has 6.38 GiB memory in use. Process 1889342 has 12.83 GiB memory in use. Process 1889541 has 9.90 GiB memory in use. Process 1889737 has 7.60 GiB memory in use. Process 1889925 has 8.28 GiB memory in use. Process 1890128 has 6.90 GiB memory in use. Process 1890318 has 5.60 GiB memory in use. Process 1890501 has 6.62 GiB memory in use. Process 1890692 has 7.14 GiB memory in use. Process 1890878 has 7.74 GiB memory in use. Of the allocated memory 5.91 GiB is allocated by PyTorch, and 202.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 136, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
92ce8ddf,"{'batch_size': 64, 'num_CL': 4, 'size_CL': 30, 'kernel': 3, 'num_HL': 4, 'latent_dim': 9, 'opt_lr': 8.508040955558067e-05, 'opt_wd': 3.2184654338785392e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 320.00 MiB. GPU 0 has a total capacty of 79.15 GiB of which 243.25 MiB is free. Process 1885097 has 6.38 GiB memory in use. Process 1889342 has 12.83 GiB memory in use. Process 1889541 has 9.90 GiB memory in use. Process 1889737 has 7.60 GiB memory in use. Process 1889925 has 8.28 GiB memory in use. Process 1890128 has 10.46 GiB memory in use. Process 1890318 has 5.75 GiB memory in use. Process 1890501 has 5.97 GiB memory in use. Process 1890692 has 3.92 GiB memory in use. Process 1890878 has 7.74 GiB memory in use. Of the allocated memory 8.04 GiB is allocated by PyTorch, and 1.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 136, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
19346b5c,"{'batch_size': 128, 'num_CL': 3, 'size_CL': 25, 'kernel': 4, 'num_HL': 4, 'latent_dim': 6, 'opt_lr': 0.00022597180166145979, 'opt_wd': 4.831795056046414e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacty of 79.15 GiB of which 157.19 MiB is free. Process 1885097 has 5.90 GiB memory in use. Process 1889342 has 12.84 GiB memory in use. Process 1889541 has 9.92 GiB memory in use. Process 1889737 has 7.61 GiB memory in use. Process 1889925 has 8.28 GiB memory in use. Process 1890128 has 10.47 GiB memory in use. Process 1890318 has 6.28 GiB memory in use. Process 1890501 has 5.97 GiB memory in use. Process 1890692 has 3.93 GiB memory in use. Process 1890878 has 7.74 GiB memory in use. Of the allocated memory 5.54 GiB is allocated by PyTorch, and 220.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 136, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
9bfcf377,"{'batch_size': 128, 'num_CL': 4, 'size_CL': 25, 'kernel': 4, 'num_HL': 4, 'latent_dim': 9, 'opt_lr': 1.0233968335530928e-05, 'opt_wd': 7.175354732580048e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 218.00 MiB. GPU 0 has a total capacty of 79.15 GiB of which 147.25 MiB is free. Process 1885097 has 6.07 GiB memory in use. Process 1889342 has 12.84 GiB memory in use. Process 1889541 has 9.92 GiB memory in use. Process 1889737 has 7.63 GiB memory in use. Process 1889925 has 7.19 GiB memory in use. Process 1890128 has 7.71 GiB memory in use. Process 1890318 has 7.67 GiB memory in use. Process 1890501 has 6.44 GiB memory in use. Process 1890692 has 5.61 GiB memory in use. Process 1890878 has 7.87 GiB memory in use. Of the allocated memory 4.96 GiB is allocated by PyTorch, and 137.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 136, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
769945ba,"{'batch_size': 64, 'num_CL': 4, 'size_CL': 29, 'kernel': 4, 'num_HL': 4, 'latent_dim': 4, 'opt_lr': 1.0076460453832675e-05, 'opt_wd': 4.975384528854212e-06}",<class 'torch.cuda.OutOfMemoryError'>,"CUDA out of memory. Tried to allocate 146.00 MiB. GPU 0 has a total capacty of 79.15 GiB of which 15.25 MiB is free. Process 1885097 has 6.07 GiB memory in use. Process 1889342 has 12.84 GiB memory in use. Process 1889541 has 9.92 GiB memory in use. Process 1889737 has 7.63 GiB memory in use. Process 1889925 has 7.19 GiB memory in use. Process 1890128 has 7.71 GiB memory in use. Process 1890318 has 5.71 GiB memory in use. Process 1890501 has 6.44 GiB memory in use. Process 1890692 has 7.70 GiB memory in use. Process 1890878 has 7.87 GiB memory in use. Of the allocated memory 6.95 GiB is allocated by PyTorch, and 230.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","  File ""/home/darlinne.soto/new_framework/ray-tune-search/hyperparameters_search.py"", line 136, in my_objective_function
    result = h_search_unit(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/h_search_unit.py"", line 23, in h_search_unit
    experiment_result = run_basic_experiment(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/run_basic_experiment.py"", line 151, in run_basic_experiment
    datasets = do_reduce(

  File ""/home/darlinne.soto/new_framework/ray-tune-search/basic/do_reduce.py"", line 121, in do_reduce
    reducer.fit(**fit_dsets)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 182, in fit
    epoch_loss, epoch_ae_loss, epoch_topo_loss = self.__one_epoch(train_data_loader, train_mode=True)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/librep/transforms/topo_ae.py"", line 85, in __one_epoch
    self.optimizer.step()

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 280, in wrapper
    out = func(*args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/optimizer.py"", line 33, in _use_grad
    ret = func(self, *args, **kwargs)

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 143, in step
    adam(

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 283, in adam
    func(params,

  File ""/home/darlinne.soto/.local/lib/python3.10/site-packages/torch/optim/adam.py"", line 508, in _multi_tensor_adam
    denom = torch._foreach_add(exp_avg_sq_sqrt, eps)
"
